---
layout: post
title: 【Method】深度学习（二）深度前馈网络
categories: Analytics
---

## 原理

深度前馈网络（deep feedforward network），也叫作前馈神经网络（feedforward neural network）或者多层感知机（multilayer perceptron, MLP），是典型的深度学习模型。前馈网络的目标是近似某个函数$$f^*$$。例如，对于分类器，$$y=f^*(x)$$将输入x映射到一个类别y。前馈网络定义了一个映射$$y=f(x;\theta)$$，并且学习参数$$\theta$$的值，使它能够得到最佳的函数近似。

这种模型被称为前向（feedforward）的，是因为信息流过x的函数，流经用于定义f的中间计算过程，最终到达输出y。在模型的输出和模型本身之间没有反馈（feedback）连接。当前馈神经网络被扩展成包含反馈连接时，它们被称为循环神经网络（recurrent neural network）。

前馈神经网络被称作网络（network）是因为它们通常用许多不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复合在一起的。例如，我们有三个函数$$f^{(1)},f^{(2)},f^{(3)}$$连接在一个链上以形成$$f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))$$。这些链式结构是神经网络中最常用的结构。在这种情况下，$$f^{(1)}$$被称为网络的第一层（first layer），$$f^{(2)}$$被称为第二层（second layer），以此类推。链的全长称为模型的深度（depth）。正是因为这个术语才出现了“深度学习”这个名字。前馈网络的最后一层被称为输出层（output layer）。在神经网络训练的过程中，我们让$$f(x)$$去匹配$$f^*(x)$$的值。训练数据为我们提供了在不同训练点上取值的、含有噪声的$$f^*(x)$$的近似实例。每个样本x都伴随着一个标签$$y \approx f^*(x)$$。训练样本直接指明了输出层在每一点x上必须做什么；它必须产生一个接近y的值。但是训练数据并没有直接指明其他层应该怎么做。学习算法必须决定如何使用这些层来产生想要的输出，但是训练数据并没有说每个单独的层应该做什么。相反，学习算法必须决定如何使用这些层来最好地实现$$f^*$$的近似。因为训练数据并没有给出这些层中的每一层所需的输出，所以这些层被称为隐藏层（hidden layer）。

最后，这些网络被称为神经网络是因为他们或多或少地受到了神经科学的启发。网络中的每个隐藏层通常都是向量值的。这些隐藏层的维数决定了模型的宽度（width）。

向量的每个元素都可以被视为起到类似一个神经元的作用。除了将层想象成向量到向量的单个函数，我们也可以把层想象成由许多并行操作的单元（unit）组成，每个单元表示一个向量到标量的函数。每个单元在某种意义上类似于一个神经元，它接收的输入来源于许多其他的单元，并计算它自己的激活值。使用多层向量值表示的想法来源于神经科学。用于计算这些表示的函数$$f^{(i)}(x)$$的选择，也或多或少地受到神经科学观测的指引，这些观测是关于生物神经元计算功能的。然而，现代的神经网络研究受到更多的是来自许多数学和工程学科的指引，并且神经网络的目标并不是完美地给大脑建模。

我们最好将前馈神经网络想成是为了实现统计泛化而设计出的函数近似机，它偶尔从我们了解的大脑中提取灵感，但并不是大脑功能的模型。

一种理解前馈网络的方式是从线性模型开始，并考虑如何克服它的局限性。线性模型，例如逻辑回归和线性回归，是非常吸引人的，因为无论通过闭解形式还是使用凸优化，它们都能高效且可靠地拟合。线性模型也有明显的缺陷，那就是该模型的能力被局限在线性函数里，所以它无法理解任何两个输入变量间的相互作用。

为了扩展线性模型来表示x的非线性函数，我们可以不把线性模型用于x本身，而是用在一个变换后的输入$$\phi(x)$$上，这里$$\phi$$是一个非线性变换。同样，我们可以使用核技巧，来得到一个基于隐含地使用$$\phi$$映射的非线性学习算法。我们可以认为$$\phi$$提供了一组描述x的特征，或者认为它提供了x的一个新的表示。

剩下的问题就是如何选择映射$$\phi$$。

1. 其中一种选择是使用一个通用的$$\phi$$，例如无限维的$$\phi$$，它隐含地用在基于RBF核的核机器上。如果$$\phi(x)$$具有足够高的维数，我们总是有足够的能力来拟合训练集，但是对于测试集的泛化往往不佳。非常通用的特征映射通常只基于局部光滑的原则，并且没有将足够的先验信息进行编码来解决高级问题。
2. 另一种选择是手动地设计$$\phi$$。在深度学习出现以前，这一直是主流的方法。这种方法对于每个单独的任务都需要人们数十年的努力，从业者各自擅长特定的领域（如语音识别或计算机视觉），并且不同领域之间很难迁移（transfer）。
3. 深度学习的策略是去学习$$\phi$$。在这种方法中，我们有一个模型$$y=f(x;\theta,w)=\phi(x;\theta)^T w.我们现在有两种参数：

这种通过学习特征来改善模型的一般化原则不仅仅适用于本章描述的前馈神经网络。它是深度学习中反复出现的主题，适用于全书描述的所有种类的模型。前馈神经网络是这个原则的应用，它学习从x到y的确定性映射并且没有反馈连接。后面出现的其他模型会把这些原则应用到学习随机映射、学习带有反馈的函数以及学习单个向量的概率分布。

### 学习XOR

#### 激活函数

如果深度学习的每一层都是线性模型，那么前馈网络作为一个整体对于输入仍然是线性的。

因此，我们必须用非线性函数来描述这些特征。大多数神经网络通过仿射变换之后紧跟着一个被称为激活函数的固定非线性函数来实现这个目标，其中仿射变换由学习到的参数控制。

我们这里使用这种策略，定义$$h=g(W^T x +c)$$，其中W是线性变换的权重矩阵，c是偏置。此前，为了描述线性回归模型，我们使用权重向量和一个标量的偏置参数来描述从输入向量到输出向量的仿射变换。现在，因为我们描述的是向量x到向量h的仿射变换，所以我们需要一整个向量的偏置阐述。

激活函数g通常选择对每个元素分别起作用的函数，有$$h_i = g(x^T W_{:,i} +c_i)$$。在现代神经网络中，默认的推荐是使用激活函数$$g(z)  =max{0,z}$$定义的整流线性单元（rectified linear unit）或者称为ReLU。

整流线性激活函数是被推荐用于大多数前馈神经网络的默认激活函数。将此函数用于线性变换的输出将产生非线性变换。然而，函数仍然非常接近线性，在这种意义上它是具有两个线性部分的分段线性函数。由于整流线性单元几乎是线性的，因此它们保留了许多使得线性模型易于使用基于梯度的方法进行优化的属性。它们还保留了许多使得线性模型能够泛化良好的属性。计算机科学的一个通用原则是，我们可以从最小的组件构建复杂的系统。就像图灵机的内存只需要能够存储0或1的状态，我们可以从整流线性函数构建一个万能函数近似器。

### 基于梯度的学习

设计和训练神经网络与使用梯度下降训练其他任何机器学习模型并没有太大不同。

我们到目前为止看到的线性模型和神经网络最大的区别，在于神经网络的非线性性导致大多数我们感兴趣的代价函数都变得非凸。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或SVM的凸优化算法那样保证全局收敛。凸优化从任何一种初始参数出发都会收敛（理论上如此——在实践中也很鲁棒但可能会遇到数值问题。）用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。对于前馈神经网络，将所有的权重值初始化为小随机数是很重要的。偏置可以初始化为零或者小的正值。

训练算法几乎总是基于使用梯度来使得代价函数下降的各种方法。一些特别的算法是对梯度下降思想的改进和提纯。还有一些更特别的，大多数是对随机梯度下降算法的改进。

我们当然也可以用梯度下降来训练诸如线性回归和支持向量机之类的模型，并且事实上当训练集相当大时这是很常用的。从这点来看，训练神经网络和训练其他任何模型并没有太大区别。计算梯度对于神经网络会略微复杂一些，但仍然可以很高效而精确地实现。之后我们将会介绍如何用反向传播算法以及它的现代扩展算法来求得梯度。

和其他机器学习模型一样，为了使用基于梯度的学习方法我们必须选择一个代价函数，并且我们必须选择如何表示模型的输出。

#### 代价函数

深度神经网络设计中的一个重要方面是代价函数的选择。幸运的是，神经网络的代价函数或多或少是和其他的参数模型例如线性模型的代价函数相同的。

在大多数情况下，我们的参数模型定义了一个分布$$p(y \mid x; \theta)$$并且我们简单地使用最大似然原理。这意味着我们使用训练数据和模型预测间的交叉熵作为代价函数。

有时，我们使用一个更简单的方法，不是预测y的完整概率分布，而是仅仅预测在给定x的条件下y的某种统计量。某些专门的损失函数允许我们来训练这些估计量的预测器。

用于训练神经网络的完整的代价函数，通常在我们这里描述的基本代价函数的基础上结合一个正则项。用于线性模型的权值衰减方法也直接适用于深度神经网络，而且是最流行的正则化策略之一。

- 使用最大似然学习条件分布

大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价。这个代价函数表示为

$$J(\theta) = -E_{x,y \sim \hat{p}_data} (y \mid x)$$

代价函数的具体形式随着模型而改变，取决于$$log p_{model}$$的具体形式。上述方程的展开形式通常会有一些项不依赖于模型的参数，我们可以舍去。例如，如果$$p_{model} (y \mid x) = N(y;f(x; \theta), I)$$，那么我们就重新得到了均方误差代价，

$$J(\theta) = \frac{1}{2} E_{w,y \sim \hat{p}_{data}} \| y -f(x;\theta) \|^2 + const$$

至少系数$$\frac{1}{2}$$和常数项不依赖于$$\theta$$。舍弃的常数是基于高斯分布的方差，在这种情况下我们选择不把它参数化。之前，我们看到了对输出分布的最大似然估计和对线性模型均方误差的最小化之间的等价性，但事实上，这种等价性并不要求$$f(x;\theta)$$用于预测高斯分布的均值。

使用最大似然来导出代价函数的方法的一个优势是，它减轻了为每个模型设计代价函数的负担。明确一个模型$$p(y \mid x)$$则自动地确定了一个代价函数$$log p(y \mid x)$$。

贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的大和具有足够的预测性，来为学习算法提供一个好的指引。饱和（变得非常平）的函数破坏了这一目标，因为它们把梯度变得非常小。这在很多情况下都会发生，因为用于产生隐藏单元或输出单元的输出的激活函数会饱和。负的对数似然帮助我们在很多模型中避免这个问题。很多输出单元都会包含一个指数函数，这在它的变量取绝对值非常大的负值时会造成饱和。负对数似然代价函数中的对数函数消除了某些输出单元中的指数效果。

用于实现最大似然估计的交叉熵代价函数有一个不同寻常的特性，那就是当它被应用于实践中经常遇到的模型时，它通常没有最小值。对于离散型输出变量，大多数模型以一种特殊的形式来参数化，即它们不能表示概率零和一，但是可以无限接近。逻辑回归是其中一个例子。对于实值的输出变量，如果模型可以控制输出分布的密度（例如，通过学习高斯输出分布的方差参数），那么它可能对正确的训练集输出赋予极其高的密度，这将导致交叉熵趋向于负无穷。之后描述的正则化技术提供了一些不同的方法来修正学习问题，使得模型不会通过这种方式来获得无限制的收益。

#### 学习条件统计量

有时我们并不是想学习一个完整的概率分布$$p(y \mid x; \theta)$$，而仅仅是想学习在给定x时y的某个条件统计量。

例如，我们可能有一个预测期$$f(x;\theta)$$，我们想用它来预测y的均值。如果我们使用一个足够强大的神经网络，我们可以认为这个神经网络能够表示一大类函数中的任何一个函数f，这个类仅仅被一些特征所限制，例如连续性和有界，而不是具有特殊的参数形式。