---
layout: post
title: 【Method】计量导论（三）统计学知识回顾
categories: Analytics
---

统计学是借助数据来认识周围世界的一门学科。统计工具可以帮助我们分析某些总体分布的未知特征。

从统计学的角度，我们能够通过抽取总体中的一个随机样本来了解总体。与总体不同，我们可以通过简单随机抽样仅仅调查一部分样本。利用统计学的方法，我们可以得到有关总体特征的初步结论，也可以对总体特征进行统计推断。

贯穿于计量经济学始终的三类统计方法分别是估计、假设检验和置信区间。其中，估计是指利用样本数据得到有关总体分布某一未知特征（如均值）的“最佳数值猜测”。假设检验首先给出关于总体的一个具体假设，然后利用样本数据来验证该假设是否成立。置信区间则是利用样本数据来估计未知总体特征的区间范围。

## 总体均值估计

假设你想知道总体Y的均值（即$$\mu_Y$$），比如刚毕业的女大学生的平均收入水平。一个常用的方法是利用n个独立同分布观测值$$Y_1,...,Y_n$$（正如前文所述，假如$$Y_1,...,Y_n$$是通过简单随机抽样抽取的，从而它们是独立同分布的）的样本均值$$\bar{Y}$$来估计这一均值$$\mu_Y$$。

### 估计量及其性质

估计量。利用样本均值$$\bar{Y}$$估计$$\mu_Y$$是常用的做法，但并不是唯一的方法。举例说明，另一种估计$$\mu_Y$$的方法是仅使用第一个观测值$$Y_1$$来估计$$\mu_Y$$。$$\bar{Y}$$和$$Y_1$$都是用来估计$$\mu_Y$$。$$\bar{Y}$$和$$Y_1$$都是用来估计$$\mu_Y$$的样本数据的函数；即二者都是$$\mu_Y$$的估计量。在重复抽样时，$$\bar{Y}$$和$$Y_1$$都会随着样本的不同而取不同的值（得到了不同的估计值）。因此，估计量$$\bar{Y}$$和$$Y_1$$都有抽样分布。实际上，$$\bar{Y}$$和$$Y_1$$只是$$\mu_Y$$众多估计量中的两个例子。

在众多可能的估计量中，如何评价一个估计量比另外一个“更好”？由于估计量是随机变量，因而这个问题可以更准确地描述为：估计量的抽样分布有哪些优良性质？一般而言，我们希望估计量至少在某种平均意义上尽可能地靠近未知的真实值；换言之，估计量的抽样分布应该尽可能紧密聚集在未知值的周围。由此可得到估计量的三个特殊优良性质：无偏性（没有偏差）、一致性和有效性。

估计量是从总体中随机抽取的样本数据的函数。而估计值是基于特定样本数据计算得到的估计量的值。由于抽样是随机的，因此估计量是随机变量，但估计值却是一个非随机的数。

无偏性。假设你多次重复利用随机样本来计算估计量的值。很自然地，你希望得到一个从平均意义上正确的结果。因此，估计量的一个优良性质是其抽样分布的均值等于$$\mu_Y$$。在这种情况下，该估计量是无偏的。用数学语言表述这一概念，即令$$\hat{\mu}_Y$$表述$$\mu_Y$$的某个估计量，如$$\bar{Y}$$或$$Y_1$$。当$$E(\hat{\mu}_Y)=\mu_Y$$时，估计量$$\hat{\mu}_Y$$是无偏的，其中$$E(\hat{\mu}_Y)$$表示抽样分布$$\hat{\mu}_Y$$的均值；否则，$$\hat{\mu}_Y$$是有偏的。

一致性。估计量$$\hat{\mu}_Y$$的另一个优良性质是当样本容量较大时，由样本的随机变化带来$$\hat{\mu}_Y$$取值的不确定性很小。更确切的说，当样本容量增大时，$$\hat{\mu}_Y$$落入真实值$$\mu_Y$$的微小邻域区间内的概率接近于1，即$$\hat{\mu}_Y$$是$$\mu_Y$$的一致性估计量。

方差和有效性。假设存在两个候选估计量$$\hat{\mu}_Y$$和$$\tilde{\mu}_Y$$，二者均满足无偏性。你将如何在二者之间做出选择？一种方法是选择一个抽样分布最集中的估计量，即在$$\hat{\mu}_Y$$和$$\tilde{\mu}_Y$$之间选择一个最小方差的估计量。如果$$\hat{\mu}_Y$$的方差比$$\tilde{\mu}_Y$$更小，则称$$\hat{\mu}_Y$$比$$\tilde{\mu}_Y$$更有效。术语“有效性”来源于此。

假设$$\hat{\mu}_Y$$是$$\mu_Y$$的一个估计量，则：

- $$\hat{\mu}_Y$$的偏差为$$E(\hat{\mu}_Y)-\mu_Y$$。
- 如果$$E(\hat{\mu}_Y) = \mu_Y$$，则$$\hat{\mu}_Y$$是$$\mu_Y$$的一个无偏估计量。
- 如果$$\hat{\mu}_Y \to \mu_Y$$，则$$\hat{\mu}_Y$$是$$\mu_Y$$的一个一致估计量。
- 令$$\tilde{\mu}_Y$$是$$\mu_Y$$的另一个估计量，且假定$$\hat{\mu}_Y$$和$$\tilde{\mu}_Y$$均是无偏的。如果$$Var(\hat{\mu}_Y) < Var(\tilde{\mu}_Y)$$，则称$$\hat{\mu}_Y$$的更有效的。

### $$\bar{Y}$$的性质

根据偏差、一致性和有效性三个原则。$$\bar{Y}$$作为$$\mu_Y$$估计量的效果究竟如何？

偏差和一致性。$$\bar{Y}$$的抽样分布已经讨论过，$$E(\bar{Y}) = \mu_Y$$，所以$$\bar{Y}$$是$$\mu_Y$$的无偏估计量。类似地，由大数定律可知，$$\bar{Y} \to \mu_Y$$，即$$\bar{Y}$$是一致的。

有效性。由于有效性涉及与其他估计量的比较，我们从比较$$\bar{Y}$$和$$Y_1$$的有效性开始。因为$$Y_1, Y_2, ..., Y_n$$是独立同分布的，$$Y_1$$抽样分布的均值为$$E(Y_1) = \mu_Y$$，因此$$Y_1$$是$$\mu_Y$$的无偏估计量，其方差为$$Var(Y_1) = \sigma_Y^2$$。根据中心极限定理，$$\bar{Y}$$的方差为$$\frac{\sigma_Y^2}{n}$$。因此，当$$n \geq 2$$时，$$\bar{Y}$$的方差小于$$Y_1$$的方差；也就是说，$$\bar{Y}$$比$$Y_1$$有效。

在$$Y_1, Y_2, ..., Y_n$$所有的加权平均类无偏估计量中，$$\bar{Y}$$是最有效的。换句话说，$$\bar{Y}$$是最佳线性无偏估计量（best linear unbiased estimator，BLUE）；即在$$Y_1, Y_2, ..., Y_n$$所有的线性函数类无偏估计量中，$$\bar{Y}$$是最有效的估计量。

$$\bar{Y}$$是$$\mu_Y$$的最小二乘估计量。在所有可能的估计量中，样本均值$$\bar{Y}$$对数据的拟合效果最好，即观测值与$$\bar{Y}$$之间的离差平方和最小。

使下式预测误差$$Y_i -m$$平方和达到最小的估计量m被称为最小二乘估计量（least squares estimator）。$$\bar{Y}$$就是$$\mu_Y$$的最小二乘估计量。

$$\sum_{i=1}^n (Y_i - m)^2$$

### 随机抽样的重要性

这一假设之所以非常重要，是因为非随机的样本会导致$$\bar{Y}$$有偏。（selection bias）

## 关于总体均值的假设检验

许多关于周围世界的假设可以简单地被表述为是或否的问题。统计学的任务是基于样本数据提供的证据回答这些问。本节描述了有关总体均值的假设检验（hypothesis tests）。

### 原假设与备择假设

统计检验的出发点是设定需要检验的假设，被称为原假设（null hypothesis）。假设检验还涉及与原假设进行比较的另一假设，被称为备择假设（alternative hypothesis），即当原假设不成立时，该假设成立。

原假设是指总体均值$$E(Y)$$取某个特定值，记作$$\mu_{Y,0}$$。原假设记作$$H_0$$。因此可表述为

$$H_0: E(Y) = \mu_{Y,0}$$

备择假设指出了当原假设不成立时，什么才是正确的。最为一般化的备择假设是$$E(Y) \neq \mu_{Y,0}$$。因为它允许了E(Y)大于或小于$$\mu_{Y,0}$$，所以被称为双边备择假设（two-sided alternative hypothesis）。双边备择假设可写为：

$$H_1: E(Y) \neq \mu_{Y,0}$$

单边备择假设也可能存在，后文将会讨论这一情况。

统计学家面临的问题就是如何利用随机抽样数据来决定是接受原假设$$H_0$$，还是拒绝它从而接受备择假设$$H_1$$。如果“接受”原假设，并不意味着统计学家支持它是正确的；相反，它仅仅是被暂时接受了，今后也可能基于其他证据拒绝它。正由于这一原因，统计假设检验可以被表述为拒绝原假设或不能拒绝原假设。

### p值

对于任意给定的样本，样本均值$$\bar{Y}$$不太可能恰好等于假设值$$\mu_{Y,0}$$。造成$$\bar{Y}$$和$$\mu_{Y,0}$$存在差异的原因可能是由于真实的均值不等于$$\mu_{Y,0}$$（即原假设是错误的），或者虽然真实值等于$$\mu_{Y,0}$$（原假设正确），但随即抽样使得$$\bar{Y}$$不等于$$\mu_{Y,0}$$，而要明确区分这两种可能性则比较困难。然而，虽然样本数据无法提供有关原假设的决定性证据，但可以通过计算概率，即利用衡量抽样不确定性的方法来检验原假设，这一计算过程涉及利用数据计算原假设的p值。

p值（p-value），也称显著性概率（significance probability），是指在原假设为真的情况下，抽取到统计量与原假设值之间的差异程度大于样本计算值与原假设之间差异程度的概率。例如，p值是指抽样得到的$$\bar{Y}$$与原假设值$$\mu_{Y,0}$$的距离大于实际计算的样本均值与原假设值距离的概率。

举例而言，假设你所收集到的最近毕业的大学生样本中，平均工资是22.64美元。则p值是指在原假设（平均工资为20元）为真的条件下，$$\bar{Y}$$的观测值与20美元（原假设下的总体均值）的差异大于实际计算得到的22.64美元与20美元之间差异的概率。