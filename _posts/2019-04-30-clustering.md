---
layout: post
title: 【Method】聚类算法
categories: Analytics
---

聚类是针对给定的样本，依据它们特征的相似度或距离，将其归并到若干个“类”或“簇”的数据分析问题。一个类是样本的一个子集。直观上，相似的样本聚集在相同的类，不相似的样本分散在不同的类。这里，样本之间的相似度或距离起着重要作用。

聚类的目的是通过得到的类或簇来发现数据的特点或对数据进行处理，在数据挖掘、模式识别等领域有着广泛的应用。聚类属于无监督学习，因为只是根据样本的相似度或距离将其进行归类，而类或簇事先并不知道。

聚类算法很多，本章介绍两种最常用的聚类算法：层次聚类（hierarchical clustering）和k均值聚类（k-means clustering）。层次聚类又有聚合（自下而上）和分裂（自上而下）两种方法。聚合法开始将每个样本各自分到一个类；之后将相距最近的两类合并，建立一个新的类，重复此操作直到满足停止条件；得到层次化的类别。分裂法开始将所有样本分到一个类；之后将已有类中相距最远的样本分到两个新的类，重复此操作直到满足停止条件；得到层次化的类别。k均值聚类是基于中心的聚类方法，通过迭代，将样本分到k个类中，使得每个样本与其所属类的中心或均值最近；得到k个“平坦的”、非层次化的类别，构成对空间的划分。k均值聚类的算法1967年由MacQueen提出。

## 聚类的基本概念

### 相似度或距离

聚类的对象是观测数据，或样本集合。假设有n个样本，每个样本由m个属性的特征向量组成。样本集合可以用矩阵X表示。

聚类的核心概念是相似度（similarity）或距离（distance），有多种相似度或距离的定义。因为相似度直接影响聚类的结果，所以其选择是聚类的根本问题。具体哪种相似度更合适取决于应用问题的特性。

1. 闵可夫斯基距离（Minkowski distance）

在聚类中，可以将样本集合看作是向量空间中点的集合，以该空间的距离表示样本之间的相似度。常用的距离有闵可夫斯基距离，特别是欧式距离。闵可夫斯基距离越大相似度越小，距离越小相似度越大。

给定样本集合X，X是m维实数向量空间$$R^m$$中点的集合，其中$$x_i,x_j \in X， x_i = (x_{1i}, x_{2i}, ..., x_{mi})^T, x_j=(x_{1j},x_{2j},...,x_{mj}^T$$，样本$$x_i$$与样本$$x_j$$的闵可夫斯基距离定义为

$$d_{ij} = (\sum_{k=1}^m \mid x_{ki} - x_{kj} \mid^p)^{\frac{1}{p}}$$

这里$$P \geq 1$$。当$$p=2$$时称为欧式距离（Euclidean distance），即

$$d_{ij} =  (\sum_{k=1}^m \mid x_{ki} - x_{kj} \mid^2)^{\frac{1}{2}}$$

当$$p=1$$时称为曼哈顿距离（Manhattan distance），即

$$d_{ij} = \sum_{k=1}^m \mid x_{ki} - x_{kj} \mid$$

当$$p=\infty$$时称为切比雪夫距离（Chebyshev distance），取各个坐标数值差的绝对值的最大值，即

$$d_{ij} = \max_k \mid x_{ki} - x_{kj} \mid$$

2. 马哈拉诺比斯距离

马哈拉诺比斯距离（Mahalanobis distance），简称马氏距离，也是另一种常用的相似度，考虑各个分量（特征）之间的相关性与各个分量的尺度无关。马哈拉诺比斯距离越大相似度越小，距离越小相似度越大。

给定一个样本集合$$X, X=(x_{ij})_{m \times n}$$，其协方差矩阵记作S。样本$$x_i$$与样本$$x_j$$之间的马哈拉诺比斯距离$$d_{ij}$$定义为

$$d_{ij} = [(x_i-x_j)^T S^{-1} (x_i-x_j)]^{\frac{1}{2}}

其中

$$x_i = (x_{1i}, x_{2i}, ..., x_{mi})^T,x_j = (x_{1j}, x_{2j}, ..., x_{mj})^T$$

当S为单位矩阵时，即样本数据的各个分量互相独立且各个分量的方差为1时，马氏距离就是欧氏距离，所以马氏距离是欧氏距离的推广。

3. 相关系数

样本之间的相似度也可以用相关系数（correlation coefficient）来表示。相关系数的绝对值越接近于1，表示样本越相似；越接近于0，表示样本越不相似。

样本$$x_i$$与样本$$x_j$$之间的相关系数定义为

$$r_{ij} = \frac{\sum_{k=1}{m}(x_{ki} - \bar{x}_i)(x_{kj}- \bar{x}_j)}{[\sum_{k=1}{m}(x_{ki} - \bar{x}_i)^2\sum_{k=1}{m}(x_{kj} - \bar{x}_j)^2]^{\frac{1}{2}}}$$

其中

$$\bar{x}_i = \frac{1}{m} \sum_{k=1}^{m} x_{ki}, \bar{x}_j = \frac{1}{m} \sum_{k=1}^{m} x_{kj}$$

4. 夹角余弦

样本之间的相似度也可以用夹角余弦（cosine）来表示。夹角余弦越接近于1，表示样本越相似；越接近于0，表示样本越不相似。

样本$$x_i$$与样本$$x_j$$之间的夹角余弦定义为

$$s_{ij} = \frac{\sum_{k=1}^{m} x_{ki} x_{kj}}{[\sum_{k=1}^m x_{ki}^2 \sum_{k=1}^m x_{kj}^2]^{\frac{1}{2}}}$$

注意不同相似度度量得到的结果并不一定一致。进行聚类时，选择适合的距离或相似度非常重要。

### 类或簇

通过聚类得到的类或簇，本质是样本的子集。如果一个聚类方法假定一个样本只能属于一个类，或类的交集为空集，那么该方法称为硬聚类（hard clustering）。否则，如果一个样本可用属于多个类，或类的交集不为空集，那么该方法称为软聚类（soft clustering）方法。本章只考虑硬聚类方法。

用G表示类或簇（cluster），用$$x_i, x_j$$表示类中的样本，用$$n_G$$表示G中样本的个数，用$$d_{ij}$$表示样本$$x_i$$与样本$$x_j$$之间的距离。类或簇有多种定义，下面给出几个常见的定义。

定义1 设T为给定的正数，若集合G中任意两个样本$$x_i,x_j$$，有

$$d_{ij} \leq T$$

则称G为一个类或簇

定义2 设T为给定的正数，若对集合G的任意样本$$x_i$$，一定存在G中的另一个样本$$x_j$$，使得

$$d_{ij} \leq T$$

则称G为一个类或簇。

定义3 设T为给定的正数，若对集合G中任意一个样本$$x_i$$，G中的另一个样本$$x_j$$满足

$$\frac{1}{n_G-1} \sum_{x_j \in G} d_{ij} \leq T$$

其中$$n_G$$为G中样本的个数，则称G为一个类或簇。

定义4 设T和V为给定的两个正数，如果集合G中任意两个样本$$x_i, x_j$$的距离$$d_{ij}$$满足

$$\frac{1}{n_G-1} \sum_{x_j \in G} d_{ij} \leq T$$

$$d_{ij} \leq V$$

则称G为一个类或簇。

以上四个定义，第一个定义最为常用，并且由它可以推出其他三个定义。

类的特征可以通过不同角度来刻画，常用的特征有下面三种：

(1) 类的均值$$\bar{x}_G$$，又称为类的中心

$$\bar{x}_G = \frac{1}{n_G}\sum_{i=1}^{n_G} x_i$$

(2) 类的直径(diameter) $$D_G$$

类的直径$$D_G$$是类中任意两个样本之间的最大距离，即

$$D_G = \max_{x_i, x_j \in G} d_{ij}$$

(3) 类的样本散步矩阵(scatter matrix)$$A_G$$与样本协方差矩阵(covariance matrix) $$S_G$$

类的样本散步矩阵$$A_G$$为

$$A_G = \sum_{i=1}^{n_G}(x_i - \bar{x}_G)(x_i - \bar{x}_G)^T$$

样本协方差矩阵$$S_G$$为

$$S_G = \frac{1}{m-1}A_G = \frac{1}{m-1} \sum_{i=1}^{n_G}(x_i - \bar{x}_G)(x_i-\bar{x}_G)^T$$

其中m为样本的维数（样本属性的个数）。

### 类与类之间的距离

下面考虑类$$G_p$$与类$$G_q$$之间的距离$$D(p,q)$$，也称为连接（linkage）。类与类之间的距离也有多种定义。

设类$$G_p$$包含$$n_p$$个样本，$$G_q$$包含$$n_q$$个样本，分别用$$\bar{x}_p$$和$$\bar{x}_q$$表示$$G_p$$和$$G_q$$的均值，即类的中心

(1) 最短距离或单连接（single linkage）

定义类$$G_p$$的样本与$$G_q$$的样本之间的最短距离为两类之间的距离

$$D_{pq} = \min{d_{ij} \mid x_i \in G_p, x_j \in G_q}$$

(2) 最长距离或完全连接（complete linkage）

定义类$$G_p$$的样本与$$G_q$$的样本之间的最长距离为两类之间的距离

$$D_{pq} = \max{d_{ij} \mid x_i \in G_p, x_j \in G_q}$$

(3) 中心距离

定义类$$G_p$$和类$$G_q$$的中心$$\bar{x}_p$$与$$\bar{x}_q$$之间的距离为两类之间的距离

$$D_{pq} = d_{\bar{x}_p \bar{x}_q}$$

(4) 平均距离

定义类$$G_p$$与类$$G_q$$任意两个样本之间距离的平均值为两类之间的距离

$$D_{pq} = \frac{1}{n_p n_q} \sum_{x_i \in G_p} \sum_{x_j \in G_q} d_{ij}$$

## 层次聚类



基于共现的相似度

基于网络的相似度

基于词向量的相似度

基于知识图谱的相似度