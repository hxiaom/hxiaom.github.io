---
layout: post
title: 【Method】深度学习正则化（六）Bagging和其他集成方法
categories: Analytics
---

## 原理

Bagging（bootstrap aggregating）是通过结合几个模型降低泛化误差的技术（Breiman, 1994）。主要想法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。这是机器学习中常规策略的一个例子，被称为模型平均（model averaging）。采用这种策略的技术被称为集成方法。

模型平均（Model averaging）奏效的原因是不同的模型通常不会在测试集上产生完全相同的误差。

假设我们有k个回归模型，假设每个模型在每个例子上的误差是$$\epsilon_i$$，这个误差服从零均值方差为$$E[\epsilon_i^2]=v$$