---
layout: post
title: 【Method】回归分析专题（二）二元被解释变量回归
categories: Analytics
---

我们经常使用二元变量做解释变量，没有造成任何问题。但当被解释变量是二元变量时，情况就变得复杂了：用一条直线去拟合取值只有0和1两个值的被解释变量，这是什么意思呢？

本章研究的二元被解释变量是一种取值有限的被解释变量，即受限被解释变量（limited dependent variable）。

## 二元被解释变量与线性概率模型

房屋抵押贷款申请能否被批准是二元被解释变量的一个例子，许多其他重要问题也常常涉及二元被解释变量。例如，学费补助对个人上大学有什么影响？青少年是否吸烟取决于什么因素？一国是否接受外国援助取决于什么因素？求职者是否成功取决于什么因素？在这些例子中，我们感兴趣的结果都是二元的：学生上大学或不上大学、青少年吸烟或不吸烟、一国接受或不接受外国援助、求职者得到或没有得到工作。

本节首先讨论二元被解释变量回归与连续被解释变量回归的区别，然后介绍一种最简单的二元被解释变量模型，即线性概率模型。

### 二元被解释变量

本章所用的实例是，种族是否是导致房屋抵押贷款申请被拒绝的因素。其中，二元被解释变量是房屋抵押贷款申请是否被拒绝。

应用于二元被解释变量的多元线性回归模型被称为线性概率模型；“线性”是指它是一条直线，而“概率模型”是指这一模型刻画了被解释变量等于1的概率。

### 线性概率模型

线性概率模型（linear probability model）是多元回归模型在被解释变量为二元变量时的称谓。由于被解释变量是二元变量，故总体回归函数表示给定X时被解释变量等于1的概率。解释变量X的稀疏$$\beta_1$$表示X变化1个单位所引起的Y=1的概率变化。同理，由回归方程估计得到的OLS预测值$$\hat{Y}_i$$表示被解释变量等于1的概率预测值，OLS估计值$$\hat{\beta}_1$$表示X变化1个单位所引起的Y=1的概率变化。

之前介绍的多元回归模型的工具几乎都可以应用到线性概率模型中。系数可以通过OLS进行估计。95%置信区间为系数估计值$$\pm 1.96$$标准误差，多个系数的假设检验可以使用F统计量，变量之间的交互作用可以使用解释变量的交互项方法进行建模。由于线性概率模型中的误差项通常都是异方差的，故有必要使用异方差-稳健标准误差进行推断。

一个无法照搬硬套的工具是$$R^2$$。当被解释变量为连续变量时，可以想象$$R^2=1$$的情形：所有的数据恰好都落在回归线上。但当被解释变量为二元变量时，这是不可能达到的，除非解释变量也是二元变量。因此，$$R^2$$在这里并不是一个特别有用的统计量。我们将在下节中讨论拟合优度。

线性概率模型

线性概率模型是多元线性回归模型在被解释变量$$Y_i$$为二元变量时的应用

$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + ... + \beta_k X_{ki} + u_i$$

由于Y是二元变量，则$$E(Y \mid X_1, X_2, ..., X_k) = P(Y=1 \mid X_1, X_2, ..., X_k)$$，因此对于线性概率模型，有

$$P(Y \mid X_1, X_2, ..., X_k) = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + ... + \beta_k X_{ki}$$

回归系数$$\beta_1$$表示在保持其他解释变量不变的情况下，$$X_1$$变化1个单位所引起的Y=1的概率变化，关于$$\beta_2, ..., \beta_m$$的理解以此类推。回归系数可以通过OLS估计得到，且通常的（异方差-稳健）OLS标准误差可以用于置信区间的构造和假设检验。

线性概率模型的缺陷。线性特征使得线性概率模型易于使用，但同时也是该模型的主要缺陷。因为概率不可能大于1，因此给定X的变化对于Y=1概率的影响一定是非线性的。