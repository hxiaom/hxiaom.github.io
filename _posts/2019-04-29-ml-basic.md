---
layout: post
title: 【Method】统计学习基础
categories: Analytics
---

Herbert A. Simon曾对“学习”给出以下定义：“如果一个系统能够通过执行某个过程改进它的性能，这就是学习。”按照这一观点，统计学习就是计算机系统通过运用数据及统计方法提高系统性能的机器学习。

统计学习的对象是数据。

统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。

统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。

统计学习由监督学习（supervised learning）、非监督学习（unsupervised learning）、半监督学习（semi-supervised learning）和强化学习（reinforcment learning）等组成。

监督学习中，统计学习方法可以概括如下：从给定的、有限的、用于学习的训练数据（training data）集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间（hypothesis space）；应用某个评价准则（evaluation criterion），从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据（test data）在给定的评价标准下有最优的预测；最优模型的选取由算法实现。

统计学习方法的三要素：模型（model）、策略（strategy）和算法（algorithm）。

实现统计学习方法的步骤如下：
1. 得到一个有限的训练数据集合；
2. 确定包含所有可能的模型的假设空间，即学习模型的集合；
3. 确定模型选择的准则，即学习的策略；
4. 实现求解最优模型的算法，即学习的算法；
5. 通过学习方法选择最优的模型；
6. 利用学习的最优模型对新数据进行预测或分析。

统计学习研究一般包括统计学习方法（statistical learning method）、统计学习理论（statistical learning theory）及统计学习应用（application of statistical learning）三个方面。统计学习方法的研究旨在开发新的学习方法；统计学习理论的研究在于探求统计学习方法的有效性与效率，以及统计学习的基本理论问题；统计学习应用的研究主要考虑将统计学习方法应用到实际问题中去，解决实际问题。

在监督学习中，每个具体的输入是一个实例（instance），通常由特征向量（feature vector）表示。这时，所有特征向量存在的空间称为特征空间（feature space）。特征空间的每一维对应于一个特征。有时假设输入空间与特征空间为相同的空间，对它们不予区分；有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。

监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y)。P(X,Y)表示分布函数，或分布密度函数。注意，在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的。训练数据与测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的。

模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间（hypothesis space）。假设空间的确定意味着学习范围的确定。

监督学习的模型可以是概率模型或非概率模型，由条件概率分布$$P(Y \mid X)$$或决策函数（decision fuction）Y=f(X)表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作$$P(y \mid x)$$或y=f(x)。

损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。

(1) 0-1损失函数（0-1 loss function）

$$ f(x)=\left\{
\begin{aligned}
1 & , & Y \neq f(X) \\
0 & , & Y = f(X) \\
\end{aligned}
\right.
$$

(2) 平方损失函数（quadratic loss function）

$$L(Y, f(X)) = (Y-f(X))^2$$

(3) 绝对损失函数（absolute loss function）

$$L(Y, f(X)) = \mid Y - f(X) \mid$$

(4) 对数损失函数（logarithmic loss function）或对数似然损失函数（log-likelihood loss function）

$$L(Y, P(Y \mid X)) = -log P(Y \mid X)$$

损失函数值越小，模型越好。由于模型的输入、输出(X,Y)是随机变量，遵循联合分布P(X,Y)，所以损失函数的期望是

$$R_{exp}(f) = E_P[L(Y,f(X))] = \int_{X \times Y} L(y,f(x))P(x,y) dx dy$$

这是理论上模型f(x)关于联合概率分布P(X,Y)的平均意义下的损失，成为风险函数（risk function）或期望损失（expected loss）。 

给定一个训练数据集

$$T={(x_1,y_1), (x_2,y_2), ...,(x_N,y_N)}$$

模型f(X)关于训练数据集的平均损失成为经验风险（empirical risk）或经验损失（empirical loss），记作$$R_{emp}$$：

$$R_{emp}(f) = \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i))$$

期望风险$$R_{exp}(f)$$是模型关于联合分布的期望损失，经验风险$$R_{emp}(f)$$是模型关于训练样本集的平均损失。根据大数定律，当样本容量N趋于无穷时，经验风险$$R_{emp}(f$$趋于期望风险$$R_{exp}(f)$$。所以一个很自然的想法是用经验风险估计期望风险。但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正。这就关系到监督学习的两个基本策略：经验风险最小化和结构风险最小化。

### 经验风险最小化与结构风险最小化

在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定。经验风险最小化（empirical risk minimization, ERM）的策略认为，经验风险最小的模型是最优的模型。根据这一策略，按照经验风险最小化求最优模型就是求解最优化问题：

$$min_{f\in F} \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i))$$

其中，F是假设空间。

当样本容量足够大，经验风险最小化能保证有很好的学习效果，在现实中被广泛采用。比如，极大似然估计（maximum likelihood estimation）就是经验风险最小化的一个例子。当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。

但是，当样本容量很小时，经验风险最小化学习的效果就未必很好，会产生“过拟合（over-fitting）”问题。

结构风险最小化（structural risk minimizatioin, SRM）是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化（regularization）。结构风险在经验风险上加上表示模型复杂度的正则化项（regularizer）或惩罚项（penalty term）。在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是

$$R_{srm}(f) = \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i)) + \lambda J(f)$$

其中J(f)为模型的复杂度，是定义在假设空间F上的泛函。模型f越复杂，复杂度J(f)j就越大。也就是说，复杂度表示了对复杂模型的惩罚。$$\lambda \geq 0$$是系数，用以权衡经验风险和模型复杂度。结构风险小的需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。

比如，贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation，MAP）就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。

### 模型评估与模型选择

训练误差的大小，对判断给定的问题是不是一个容易学习的问题是有意义的，但本质上不重要。测试误差反映了学习方法对未知的测试数据集的预测能力，是学习中的重要概念。显然，给定两种学习方法，测试误差小的方法具有更好的预测能力，是更有效的方法。通常将学习方法对未知数据的预测能力称为泛化能力（generalization ability）。

#### 过拟合与模型选择

当假设空间含有不同复杂度（例如，不同的参数个数）的模型时，就要面临模型选择（model selection）的问题，我们希望选择或学习一个合适的模型。如果在假设空间中存在“真”模型，那么所选择的模型应该逼近真模型。具体地，所选择的模型要与真模型的参数个数相同，所选择的模型的参数向量与真模型的参数向量相近。

如果一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合（over-fitting）。过拟合是指学习时选择的模型所包含的参数过多，以至于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。可以说模型选择旨在避免过拟合并提高模型的预测能力。

当模型的复杂度增大时，训练误差会逐渐减小并趋向于0；而测试误差会先减小，达到最小值后又增大。当选择的模型复杂度过大时，过拟合现象就会发生。这样，在学习时就要防止过拟合，进行最优的模型选择，即选择复杂度适当的模型，以达到使测试误差最小的学习目的。下面介绍两种常用的模型选择方法：正则化与交叉验证。

### 正则化与交叉验证

#### 正则化

模型选择的典型方法是正则化（regularization）。正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项（regularizer）或惩罚项（penalty term）。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如，正则化项可以是模型参数向量的范数。

正则化一般具有如下形式：

$$min_{f \in F} \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i)) + \lambda J(f)$$

其中，第1项是经验风险，第2项是正则化项，$$\lambda \geq 0$$为调整两者之间关系的系数。

正则化项可以取不同的形式。例如，回归问题中，损失函数是平方损失，正则化项可以是参数向量的$$L_2$$范数：

$$L(w) = \frac{1}{N} \sum_{i=1}^N (f(x_i;w) - y_i)^2 + \frac{\lambda}{2} \| w \|^2$$

正则化项也可以是参数向量的$$L_1$$范数：

$$L(w) = \frac{1}{N} \sum_{i=1}^N (f(x_i;w) - y_i)^2 + \lambda \| w \|_1$$

正则化符合奥卡姆剃刀（Occam's razor）原理。奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应该选择的模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。可以假设复杂的模型有较小的先验赶驴，简单的模型有较大的先验概率。

#### 交叉验证

另一种常用的模型选择方法是交叉验证（cross validation）。

如果给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分别是训练集（training set）、验证集（validation set）和测试集（test set）。训练集用来训练模型，验证机用与模型的选择，而测试集用于最终对学习方法的评估。在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。由于验证集有足够多的数据，用它对模型进行选择也是有效的。

但是，在许多实际应用中数据是不充足的。为了选择好的模型，可以采用交叉验证方法。交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集和测试集，在此基础上反复地进行训练、测试以及模型选择。

（1）简单交叉验证

简单交叉验证方法是：首先随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集（例如，70%的数据为训练集，30%的数据为测试集）；然后用训练集在各种条件下（例如，不同的参数个数）训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。

（2）S折交叉验证

应用最多的是S折交叉验证（S-fold cross validation），方法如下：首先随机地将已给数据切分为S个互不相交的大小相同的子集；然后利用S-1个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S种选择重复进行；最后选出S次评测中平均测试误差最小的模型。

（3）留一交叉验证

S折交叉验证的特殊形式是S=N，称为留一交叉验证（leave-one-out cross validation），往往在数据缺乏的情况下使用。这里，N是给定数据集的容量。

### 泛化能力

#### 泛化误差

学习方法的泛化能力（generalization ability）是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力。但这种评价是依赖于测试数据集的。因为测试数据集是有限的，很有可能由此得到的评价结果是不可靠的。统计学习理论试图从理论上对学习方法的泛化能力进行分析。

首先给出泛化误差的定义。如果学到的模型是$$\hat{f}$$，那么用这个模型对未知数据预测的误差即为泛化误差（generalization error）

$$R_{exp}(\hat{f}) = E_P[L(Y, \hat{f}(X))] = \int_{X \time Y} L(y, \hat{f}(x))P(x,y) dx dy$$

泛化误差反映了学习方法的泛化能力，如果一种方法学习的模型比另一种方法学习的模型具有更小的泛化误差，那么这种方法就更有效。事实上，泛化误差就是所学习到的模型的期望风险。

#### 泛化误差上界

学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称为泛化误差上界（generalization error bound）。具体来说，就是通过比较两种学习方法的泛化误差上界来比较它们的优劣。泛化误差上界通常具有以下性质：它是样本容量的函数，当样本容量增加时，泛化上界趋于0；它是假设空间容量（capacity）的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大。

泛化误差上界：对二分类问题，当假设空间是有限个函数的集合$$F={f_1, f_2, ..., f_d}$$时，对任意一个函数$$f \in F$$，至少以概率$$1-\delta$$，以下不等式成立：

$$R(f) \leq \hat{R}(f) + \varepsilon (d, N, \delta)$$

其中，

$$\varepsilon (d, N, \delta) = \sqrt{\frac{1}{2N} (log d + log \frac{1}{\delta})}$$

不等式左端$$R(f)$$是泛化误差，右端即为泛化误差上界。第1项是训练误差，训练误差越小，泛化误差也越小。第2项$$\varepsilon (d,N, \delta)$$是N的单调递减函数，当N趋于无穷时趋于0；同时它也是$$\sqrt{log d}$$阶的函数，假设空间F包含的函数越多，其值越大。

### 生成模型和判别模型

监督学习方法又可以分为生成方法（generative approach）和判别方法（discriminative approach）。所学到的模型分别称为生成模型（generative model）和判别模型（discriminative model）。

生成方法由数据学习联合概率分布P(X,Y)，然后求出条件概率分布$$P(X \mid Y)$$作为预测的模型，即生成模型：

$$P(Y \mid X) = \frac{P(X,Y)}{P(X)}$$

这样的方法之所以称为生成方法，是因为模型表示了给定输入X产生输出Y的生成关系。典型的生成模型有：朴素贝叶斯法和隐马尔科夫模型。

判别方法由数据直接学习决策函数f(X)或者条件概率分布$$P(Y \mid X)$$作为预测的模型，即判别模型。判别方法关心的是对给定的输入X，应该预测什么样的输出Y。典型的判别模型包括：k近邻法、感知机、决策树、逻辑斯蒂回归模型、最大熵模型、支持向量机、提升方法和条件随机场等。

在监督学习中，生成方法和判别方法各有优缺点，适合于不同条件下的学习问题。

生成方法的特点：生成方法可以还原出联合概率分P(X,Y)，而判别方法则不能；生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。

判别方法的特点：判别方法直接学习都是条件概率$$P(Y \mid X)$$或决策函数f(X)，直接面对预测，往往学习的准确率更高；由于直接学习$$P(Y \mid X)$$或f(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。

### 分类问题、标注问题和回归问题

分类问题：在监督学习中，当输出变量Y取有限个离散值时，预测问题便成为分类问题。

标注问题：可以认为标注问题（tagging）是分类问题的一个推广，标注问题又是更复杂的结构预测（structure prediction）问题的简单形式。标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。标注问题的目标在于学习一个模型，使它能够观测序列给出标记序列作为预测。注意，可能的标记个数是有限的，但其组合所成的标记序列的个数是依序列长度呈指数级增长的。

回归问题：回归用于预测输入变量（自变量）和输出变量（因变量）之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。回归模型正是表示从输入变量到输出变量之间的映射的函数。回归问题的学习等价于函数拟合：选择一条函数曲线使其更好地拟合已知数据且很好地预测未知数据。

## 参考文献

- 统计学习方法 李航 第1章