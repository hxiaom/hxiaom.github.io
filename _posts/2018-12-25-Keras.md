---
layout: post
title: Keras：基于python的深度学习库
categories: Analytics
---

* TOC
{:toc}

[Keras中文文档](https://keras.io/zh/)

Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

如果你在以下情况下需要深度学习库，请使用 Keras：
- 允许简单而快速的原型设计（由于用户友好，高度模块化，可扩展性）。
- 同时支持卷积神经网络和循环神经网络，以及两者的组合。
- 在 CPU 和 GPU 上无缝运行。

## Keras 深度学习基本步骤

### 1. Build a model

```
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(units=64, activation='relu', input_dim=100))
model.add(Dense(units=10, activation='softmax'))
```
- 模型需要知道它所期望的输入的尺寸。出于这个原因，顺序模型中的第一层（只有第一层，因为下面的层可以自动地推断尺寸）需要接收关于其输入尺寸的信息。
    - 传递一个 input_shape 参数给第一层。它是一个表示尺寸的元组 (一个整数或 None 的元组，其中 None 表示可能为任何正整数)。在 input_shape 中不包含数据的 batch 大小。
    - 某些 2D 层，例如 Dense，支持通过参数 input_dim 指定输入尺寸，某些 3D 时序层支持 input_dim 和 input_length 参数。
    - 如果你需要为你的输入指定一个固定的 batch 大小（这对 stateful RNNs 很有用），你可以传递一个 batch_size 参数给一个层。如果你同时将 batch_size=32 和 input_shape=(6, 8) 传递给一个层，那么每一批输入的尺寸就为 (32，6，8)。

### 2. Compile a model

```
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
```
- 在训练模型之前，您需要配置学习过程，这是通过 compile 方法完成的。它接收三个参数：
    - 优化器 optimizer。它可以是现有优化器的字符串标识符，如 rmsprop 或 adagrad，也可以是 Optimizer 类的实例。详见：optimizers。
    - 损失函数 loss，模型试图最小化的目标函数。它可以是现有损失函数的字符串标识符，如 categorical_crossentropy 或 mse，也可以是一个目标函数。详见：losses。
    - 评估标准 metrics。对于任何分类问题，你都希望将其设置为 metrics = ['accuracy']。评估标准可以是现有的标准的字符串标识符，也可以是自定义的评估标准函数。评价函数和 损失函数 相似，只不过评价函数的结果不会用于训练过程中。

### 3. Train a model

```
model.fit(x_train, y_train, epochs=5, batch_size=32)
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)
```

### 4. Predict based on model

```
classes = model.predict(x_test, batch_size=128)
```

## Q & A

### 如何在 GPU 上运行 Keras?
如果你以 TensorFlow 或 CNTK 后端运行，只要检测到任何可用的GPU，那么代码将自动在GPU上运行。

### "sample", "batch", "epoch" 分别是什么？

为了正确地使用 Keras，以下是必须了解和理解的一些常见定义：

- Sample: 样本，数据集中的一个元素，一条数据。例1: 在卷积神经网络中，一张图像是一个样本。例2: 在语音识别模型中，一段音频是一个样本。
- Batch: 批，含有 N 个样本的集合。每一个 batch 的样本都是独立并行处理的。在训练时，一个 batch 的结果只会用来更新一次模型。  - 一个 batch 的样本通常比单个输入更接近于总体输入数据的分布，batch 越大就越近似。然而，每个 batch 将花费更长的时间来处理，并且仍然只更新模型一次。在推理（评估/预测）时，建议条件允许的情况下选择一个尽可能大的 batch，（因为较大的 batch 通常评估/预测的速度会更快）。
- Epoch: 轮次，通常被定义为 「在整个数据集上的一轮迭代」，用于训练的不同的阶段，这有利于记录和定期评估。当在 Keras 模型的 fit 方法中使用 evaluation_data 或 evaluation_split 时，评估将在每个 epoch 结束时运行。在 Keras 中，可以添加专门的用于在 epoch 结束时运行的 callbacks 回调。例如学习率变化和模型检查点（保存）。

### 如何保存 Keras 模型？

你可以使用 model.save(filepath) 将 Keras 模型保存到单个 HDF5 文件中，该文件将包含：

- 模型的结构，允许重新创建模型
- 模型的权重
- 训练配置项（损失函数，优化器）
- 优化器状态，允许准确地从你上次结束的地方继续训练。

你可以使用 keras.models.load_model(filepath) 重新实例化模型。load_model 还将负责使用保存的训练配置项来编译模型（除非模型从未编译过）。

```
from keras.models import load_model

model.save('my_model.h5')  # 创建 HDF5 文件 'my_model.h5'
del model  # 删除现有模型

# 返回一个编译好的模型
# 与之前那个相同
model = load_model('my_model.h5')
```

### 在验证集的误差不再下降时，如何中断训练？

你可以使用 EarlyStopping 回调函数：

``` python
from keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=2)
model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])
```

### 在训练过程中数据是否会混洗？

是的，如果 model.fit中的 shuffle参数设置为 True（默认值），则训练数据将在每个 epoch 混洗。

验证集永远不会混洗。

### 如何在每个 epoch 后记录训练集和验证集的误差和准确率？

model.fit 方法返回一个 History 回调，它具有包含连续误差的列表和其他度量的 history 属性。

``` python
hist = model.fit(x, y, validation_split=0.2)
print(hist.history)
```

## Keras 模型

关于 Keras 模型
在 Keras 中有两类主要的模型：**Sequential 顺序模型 和 使用函数式 API 的 Model 类模型**。

这些模型有许多共同的方法和属性：

- model.layers 是包含模型网络层的展平列表。
- model.inputs 是模型输入张量的列表。
- model.outputs 是模型输出张量的列表。
- model.summary() 打印出模型概述信息。 它是 utils.print_summary 的简捷调用。
- model.get_config() 返回包含模型配置信息的字典。
- model.get_weights() 返回模型中所有权重张量的列表，类型为 Numpy 数组。
- model.set_weights(weights) 从 Numpy 数组中为模型设置权重。列表中的数组必须与 get_weights() 返回的权重具有相同的尺寸。
- model.to_json() 以 JSON 字符串的形式返回模型的表示。请注意，该表示不包括权重，仅包含结构。
- model.to_yaml() 以 YAML 字符串的形式返回模型的表示。请注意，该表示不包括权重，只包含结构。
- model.save_weights(filepath) 将模型权重存储为 HDF5 文件。
- model.load_weights(filepath, by_name=False): 从 HDF5 文件（由 save_weights 创建）中加载权重。默认情况下，模型的结构应该是不变的。 如果想将权重载入不同的模型（部分层相同）， 设置 by_name=True 来载入那些名字相同的层的权重。

### Sequential 模型 API

``` python
# compile
# 用于配置训练模型。
compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)

# fit
# 以固定数量的轮次（数据集上的迭代）训练模型。
fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)

# evaluate
# 在测试模式，返回误差值和评估标准值。计算逐批次进行。
evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)

# predict
# 为输入样本生成输出预测。计算逐批次进行。
predict(self, x, batch_size=None, verbose=0, steps=None)

# train_on_batch
# 一批样本的单次梯度更新。
train_on_batch(self, x, y, class_weight=None, sample_weight=None)

# test_on_batch
# 在一批样本上评估模型。
test_on_batch(self, x, y, sample_weight=None)

# predict_on_batch
# 返回一批样本的模型预测值。
predict_on_batch(self, x)

# fit_generator
# 使用 Python 生成器或 Sequence 实例逐批生成的数据，按批次训练模型。
fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)

# evaluate_generator
# 在数据生成器上评估模型。这个生成器应该返回与 test_on_batch 所接收的同样的数据。
evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)

# predict_generator
# 为来自数据生成器的输入样本生成预测。这个生成器应该返回与 predict_on_batch 所接收的同样的数据。
predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)

# get_layer
# 根据名称（唯一）或索引值查找网络层。
get_layer(self, name=None, index=None)
```

### Model 类 API

``` python
# compile
# 用于配置训练模型。
compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)

# fit
# 以固定数量的轮次（数据集上的迭代）训练模型。
fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)

# evaluate
# 在测试模式下返回模型的误差值和评估标准值。
evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)

# predict
# 为输入样本生成输出预测。
predict(self, x, batch_size=None, verbose=0, steps=None)

# train_on_batch
# 运行一批样品的单次梯度更新。
train_on_batch(self, x, y, sample_weight=None, class_weight=None)

# test_on_batch
# 在一批样本上测试模型。
test_on_batch(self, x, y, sample_weight=None)

# predict_on_batch
# 返回一批样本的模型预测值。
predict_on_batch(self, x)

# fit_generator
# 使用 Python 生成器（或 Sequence 实例）逐批生成的数据，按批次训练模型。
fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)

# predict_generator
# 为来自数据生成器的输入样本生成预测。
predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)

# get_layer
# 根据名称（唯一）或索引值查找网络层。
get_layer(self, name=None, index=None)
```

## Keras 网络层

所有Keras层都有很多共同的函数：

- layer.get_weights(): 以含有Numpy矩阵的列表形式返回层的权重。
- layer.set_weights(weights): 从含有Numpy矩阵的列表中设置层的权重（与get_weights的输出形状相同）。
- layer.get_config(): 返回包含层配置的字典。

如果一个层具有单个节点 (i.e. 如果它不是共享层), 你可以得到它的输入张量，输出张量，输入尺寸和输出尺寸:

- layer.input
- layer.output
- layer.input_shape
- layer.output_shape

如果层有多个节点 (参见: 层节点和共享层的概念), 您可以使用以下函数:

- layer.get_input_at(node_index)
- layer.get_output_at(node_index)
- layer.get_input_shape_at(node_index)
- layer.get_output_shape_at(node_index)

### 核心网络层

#### Dense

就是普通的全连接层。

Dense 实现以下操作： output = activation(dot(input, kernel) + bias) 其中 activation 是按逐个元素计算的激活函数，kernel 是由网络层创建的权值矩阵，以及 bias 是其创建的偏置向量 (只在 use_bias 为 True 时才有用)。

``` python
keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
```

#### Activation

将激活函数应用于输出。

``` python
keras.layers.Activation(activation)
```

#### Dropout

将 Dropout 应用于输入。

Dropout 包括在训练中每次更新时， 将输入单元的按比率随机设置为 0， 这有助于防止过拟合。

``` python
keras.layers.Dropout(rate, noise_shape=None, seed=None)
```

#### Flatten

将输入展平。不影响批量大小。

``` python
keras.layers.Flatten(data_format=None)
```

#### Input

Input() 用于实例化 Keras 张量。

Keras 张量是底层后端(Theano, TensorFlow or CNTK) 的张量对象，我们增加了一些特性，使得能够通过了解模型的输入 和输出来构建Keras模型。

``` python
keras.engine.input_layer.Input()
```

#### Reshape

将输入重新调整为特定的尺寸。

``` python
keras.layers.Reshape(target_shape)
```

#### Permute

根据给定的模式置换输入的维度。

在某些场景下很有用，例如将 RNN 和 CNN 连接在一起。

``` python
keras.layers.Permute(dims)
```

#### 