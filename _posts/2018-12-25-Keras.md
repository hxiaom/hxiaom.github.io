---
layout: post
title: 【Method】Keras
categories: Analytics
---

* TOC
{:toc}

[Keras中文文档](https://keras.io/zh/)

Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

如果你在以下情况下需要深度学习库，请使用 Keras：
- 允许简单而快速的原型设计（由于用户友好，高度模块化，可扩展性）。
- 同时支持卷积神经网络和循环神经网络，以及两者的组合。
- 在 CPU 和 GPU 上无缝运行。

## Keras 深度学习基本步骤

### 1. Build a model

```
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(units=64, activation='relu', input_dim=100))
model.add(Dense(units=10, activation='softmax'))
```
- 模型需要知道它所期望的输入的尺寸。出于这个原因，顺序模型中的第一层（只有第一层，因为下面的层可以自动地推断尺寸）需要接收关于其输入尺寸的信息。
    - 传递一个 input_shape 参数给第一层。它是一个表示尺寸的元组 (一个整数或 None 的元组，其中 None 表示可能为任何正整数)。在 input_shape 中不包含数据的 batch 大小。
    - 某些 2D 层，例如 Dense，支持通过参数 input_dim 指定输入尺寸，某些 3D 时序层支持 input_dim 和 input_length 参数。
    - 如果你需要为你的输入指定一个固定的 batch 大小（这对 stateful RNNs 很有用），你可以传递一个 batch_size 参数给一个层。如果你同时将 batch_size=32 和 input_shape=(6, 8) 传递给一个层，那么每一批输入的尺寸就为 (32，6，8)。

### 2. Compile a model

```
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
```
- 在训练模型之前，您需要配置学习过程，这是通过 compile 方法完成的。它接收三个参数：
    - 优化器 optimizer。它可以是现有优化器的字符串标识符，如 rmsprop 或 adagrad，也可以是 Optimizer 类的实例。详见：optimizers。
    - 损失函数 loss，模型试图最小化的目标函数。它可以是现有损失函数的字符串标识符，如 categorical_crossentropy 或 mse，也可以是一个目标函数。详见：losses。
    - 评估标准 metrics。对于任何分类问题，你都希望将其设置为 metrics = ['accuracy']。评估标准可以是现有的标准的字符串标识符，也可以是自定义的评估标准函数。评价函数和 损失函数 相似，只不过评价函数的结果不会用于训练过程中。

### 3. Train a model

```
model.fit(x_train, y_train, epochs=5, batch_size=32)
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)
```

### 4. Predict based on model

```
classes = model.predict(x_test, batch_size=128)
```

## Q & A

### 如何在 GPU 上运行 Keras?
如果你以 TensorFlow 或 CNTK 后端运行，只要检测到任何可用的GPU，那么代码将自动在GPU上运行。

### "sample", "batch", "epoch" 分别是什么？

为了正确地使用 Keras，以下是必须了解和理解的一些常见定义：

- Sample: 样本，数据集中的一个元素，一条数据。例1: 在卷积神经网络中，一张图像是一个样本。例2: 在语音识别模型中，一段音频是一个样本。
- Batch: 批，含有 N 个样本的集合。每一个 batch 的样本都是独立并行处理的。在训练时，一个 batch 的结果只会用来更新一次模型。  - 一个 batch 的样本通常比单个输入更接近于总体输入数据的分布，batch 越大就越近似。然而，每个 batch 将花费更长的时间来处理，并且仍然只更新模型一次。在推理（评估/预测）时，建议条件允许的情况下选择一个尽可能大的 batch，（因为较大的 batch 通常评估/预测的速度会更快）。
- Epoch: 轮次，通常被定义为 「在整个数据集上的一轮迭代」，用于训练的不同的阶段，这有利于记录和定期评估。当在 Keras 模型的 fit 方法中使用 evaluation_data 或 evaluation_split 时，评估将在每个 epoch 结束时运行。在 Keras 中，可以添加专门的用于在 epoch 结束时运行的 callbacks 回调。例如学习率变化和模型检查点（保存）。

### 如何保存 Keras 模型？

你可以使用 model.save(filepath) 将 Keras 模型保存到单个 HDF5 文件中，该文件将包含：

- 模型的结构，允许重新创建模型
- 模型的权重
- 训练配置项（损失函数，优化器）
- 优化器状态，允许准确地从你上次结束的地方继续训练。

你可以使用 keras.models.load_model(filepath) 重新实例化模型。load_model 还将负责使用保存的训练配置项来编译模型（除非模型从未编译过）。

```
from keras.models import load_model

model.save('my_model.h5')  # 创建 HDF5 文件 'my_model.h5'
del model  # 删除现有模型

# 返回一个编译好的模型
# 与之前那个相同
model = load_model('my_model.h5')
```

### 在验证集的误差不再下降时，如何中断训练？

你可以使用 EarlyStopping 回调函数：

``` python
from keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=2)
model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])
```

### 在训练过程中数据是否会混洗？

是的，如果 model.fit中的 shuffle参数设置为 True（默认值），则训练数据将在每个 epoch 混洗。

验证集永远不会混洗。

### 如何在每个 epoch 后记录训练集和验证集的误差和准确率？

model.fit 方法返回一个 History 回调，它具有包含连续误差的列表和其他度量的 history 属性。

``` python
hist = model.fit(x, y, validation_split=0.2)
print(hist.history)
```

## Keras 模型

关于 Keras 模型
在 Keras 中有两类主要的模型：**Sequential 顺序模型 和 使用函数式 API 的 Model 类模型**。

这些模型有许多共同的方法和属性：

- model.layers 是包含模型网络层的展平列表。
- model.inputs 是模型输入张量的列表。
- model.outputs 是模型输出张量的列表。
- model.summary() 打印出模型概述信息。 它是 utils.print_summary 的简捷调用。
- model.get_config() 返回包含模型配置信息的字典。
- model.get_weights() 返回模型中所有权重张量的列表，类型为 Numpy 数组。
- model.set_weights(weights) 从 Numpy 数组中为模型设置权重。列表中的数组必须与 get_weights() 返回的权重具有相同的尺寸。
- model.to_json() 以 JSON 字符串的形式返回模型的表示。请注意，该表示不包括权重，仅包含结构。
- model.to_yaml() 以 YAML 字符串的形式返回模型的表示。请注意，该表示不包括权重，只包含结构。
- model.save_weights(filepath) 将模型权重存储为 HDF5 文件。
- model.load_weights(filepath, by_name=False): 从 HDF5 文件（由 save_weights 创建）中加载权重。默认情况下，模型的结构应该是不变的。 如果想将权重载入不同的模型（部分层相同）， 设置 by_name=True 来载入那些名字相同的层的权重。

### Sequential 模型 API

``` python
# compile
# 用于配置训练模型。
compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)

# fit
# 以固定数量的轮次（数据集上的迭代）训练模型。
fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)

# evaluate
# 在测试模式，返回误差值和评估标准值。计算逐批次进行。
evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)

# predict
# 为输入样本生成输出预测。计算逐批次进行。
predict(self, x, batch_size=None, verbose=0, steps=None)

# train_on_batch
# 一批样本的单次梯度更新。
train_on_batch(self, x, y, class_weight=None, sample_weight=None)

# test_on_batch
# 在一批样本上评估模型。
test_on_batch(self, x, y, sample_weight=None)

# predict_on_batch
# 返回一批样本的模型预测值。
predict_on_batch(self, x)

# fit_generator
# 使用 Python 生成器或 Sequence 实例逐批生成的数据，按批次训练模型。
fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)

# evaluate_generator
# 在数据生成器上评估模型。这个生成器应该返回与 test_on_batch 所接收的同样的数据。
evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)

# predict_generator
# 为来自数据生成器的输入样本生成预测。这个生成器应该返回与 predict_on_batch 所接收的同样的数据。
predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)

# get_layer
# 根据名称（唯一）或索引值查找网络层。
get_layer(self, name=None, index=None)
```

### Model 类 API

``` python
# compile
# 用于配置训练模型。
compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)

# fit
# 以固定数量的轮次（数据集上的迭代）训练模型。
fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)

# evaluate
# 在测试模式下返回模型的误差值和评估标准值。
evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)

# predict
# 为输入样本生成输出预测。
predict(self, x, batch_size=None, verbose=0, steps=None)

# train_on_batch
# 运行一批样品的单次梯度更新。
train_on_batch(self, x, y, sample_weight=None, class_weight=None)

# test_on_batch
# 在一批样本上测试模型。
test_on_batch(self, x, y, sample_weight=None)

# predict_on_batch
# 返回一批样本的模型预测值。
predict_on_batch(self, x)

# fit_generator
# 使用 Python 生成器（或 Sequence 实例）逐批生成的数据，按批次训练模型。
fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)

# predict_generator
# 为来自数据生成器的输入样本生成预测。
predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)

# get_layer
# 根据名称（唯一）或索引值查找网络层。
get_layer(self, name=None, index=None)
```

## Keras 网络层

所有Keras层都有很多共同的函数：

- layer.get_weights(): 以含有Numpy矩阵的列表形式返回层的权重。
- layer.set_weights(weights): 从含有Numpy矩阵的列表中设置层的权重（与get_weights的输出形状相同）。
- layer.get_config(): 返回包含层配置的字典。

如果一个层具有单个节点 (i.e. 如果它不是共享层), 你可以得到它的输入张量，输出张量，输入尺寸和输出尺寸:

- layer.input
- layer.output
- layer.input_shape
- layer.output_shape

如果层有多个节点 (参见: 层节点和共享层的概念), 您可以使用以下函数:

- layer.get_input_at(node_index)
- layer.get_output_at(node_index)
- layer.get_input_shape_at(node_index)
- layer.get_output_shape_at(node_index)

### 核心网络层

#### Dense

就是普通的全连接层。

Dense 实现以下操作： output = activation(dot(input, kernel) + bias) 其中 activation 是按逐个元素计算的激活函数，kernel 是由网络层创建的权值矩阵，以及 bias 是其创建的偏置向量 (只在 use_bias 为 True 时才有用)。

``` python
keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
```

#### Activation

将激活函数应用于输出。

``` python
keras.layers.Activation(activation)
```

#### Dropout

将 Dropout 应用于输入。

Dropout 包括在训练中每次更新时， 将输入单元的按比率随机设置为 0， 这有助于防止过拟合。

``` python
keras.layers.Dropout(rate, noise_shape=None, seed=None)
```

#### Flatten

将输入展平。不影响批量大小。

``` python
keras.layers.Flatten(data_format=None)
```

#### Input

Input() 用于实例化 Keras 张量。

Keras 张量是底层后端(Theano, TensorFlow or CNTK) 的张量对象，我们增加了一些特性，使得能够通过了解模型的输入 和输出来构建Keras模型。

``` python
keras.engine.input_layer.Input()
```

#### Reshape

将输入重新调整为特定的尺寸。

``` python
keras.layers.Reshape(target_shape)
```

#### Permute

根据给定的模式置换输入的维度。

在某些场景下很有用，例如将 RNN 和 CNN 连接在一起。

``` python
keras.layers.Permute(dims)
```

#### RepeatVector

将输入重复 n 次。

``` python
keras.layers.RepeatVector(n)
```

#### Lambda

将任意表达式封装为 Layer 对象。

``` python
keras.layers.Lambda(function, output_shape=None, mask=None, arguments=None)
```

#### ActivityRegularization

网络层，对基于代价函数的输入活动应用一个更新。

``` python
keras.layers.ActivityRegularization(l1=0.0, l2=0.0)
```

#### Masking

使用覆盖值覆盖序列，以跳过时间步。

对于输入张量的每一个时间步（张量的第一个维度）， 如果所有时间步中输入张量的值与 mask_value 相等， 那么这个时间步将在所有下游层被覆盖 (跳过) （只要它们支持覆盖）。

如果任何下游层不支持覆盖但仍然收到此类输入覆盖信息，会引发异常。

``` python
keras.layers.Masking(mask_value=0.0)
```

#### SpatialDropout1D

Dropout 的 Spatial 1D 版本

此版本的功能与 Dropout 相同，但它会丢弃整个 1D 的特征图而不是丢弃单个元素。如果特征图中相邻的帧是强相关的（通常是靠前的卷积层中的情况），那么常规的 dropout 将无法使激活正则化，且导致有效的学习速率降低。在这种情况下，SpatialDropout1D 将有助于提高特征图之间的独立性，应该使用它来代替 Dropout。

``` python
keras.layers.SpatialDropout1D(rate)
```

#### SpatialDropout2D

Dropout 的 Spatial 2D 版本

此版本的功能与 Dropout 相同，但它会丢弃整个 2D 的特征图而不是丢弃单个元素。如果特征图中相邻的像素是强相关的（通常是靠前的卷积层中的情况），那么常规的 dropout 将无法使激活正则化，且导致有效的学习速率降低。在这种情况下，SpatialDropout2D 将有助于提高特征图之间的独立性，应该使用它来代替 dropout。

``` python
keras.layers.SpatialDropout2D(rate, data_format=None)
```

#### SpatialDropout3D

Dropout 的 Spatial 3D 版本

此版本的功能与 Dropout 相同，但它会丢弃整个 3D 的特征图而不是丢弃单个元素。如果特征图中相邻的体素是强相关的（通常是靠前的卷积层中的情况），那么常规的 dropout 将无法使激活正则化，且导致有效的学习速率降低。在这种情况下，SpatialDropout3D 将有助于提高特征图之间的独立性，应该使用它来代替 dropout。

``` python
keras.layers.SpatialDropout3D(rate, data_format=None)
```

### 卷积层 Convolutional

### 池化层 Pooling

### 局部链接层 Locally-connected

### 循环层 Recurrent

### 嵌入层 Embedding

### 融合层 Merge

### 高级激活层 Advanced Activations

### 标准化层 Normalization

### 噪声层 Noise

### 层封装器 wrappers


## 数据预处理

### 序列预处理

#### TimeseriesGenerator

用于生成批量时序数据的实用工具类。

这个类以一系列由相等间隔以及一些时间序列参数（例如步长、历史长度等）汇集的数据点作为输入，以生成用于训练/验证的批次数据。

``` python
keras.preprocessing.sequence.TimeseriesGenerator(data, targets, length, sampling_rate=1, stride=1, start_index=0, end_index=None, shuffle=False, reverse=False, batch_size=128)
```

#### pad_sequences

将多个序列截断或补齐为相同长度。

该函数将一个 num_samples 的序列（整数列表）转化为一个 2D Numpy 矩阵，其尺寸为 (num_samples, num_timesteps)。 num_timesteps 要么是给定的 maxlen 参数，要么是最长序列的长度。

比 num_timesteps 短的序列将在末端以 value 值补齐。

比 num_timesteps 长的序列将会被截断以满足所需要的长度。补齐或截断发生的位置分别由参数 pading 和 truncating 决定。

向前补齐为默认操作。

``` python
keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)
```

#### skipgrams

生成 skipgram 词对。

该函数将一个单词索引序列（整数列表）转化为以下形式的单词元组：

- （单词, 同窗口的单词），标签为 1（正样本）。
- （单词, 来自词汇表的随机单词），标签为 0（负样本）。

``` python
keras.preprocessing.sequence.skipgrams(sequence, vocabulary_size, window_size=4, negative_samples=1.0, shuffle=True, categorical=False, sampling_table=None, seed=None)
```

#### make_sampling_table

生成一个基于单词的概率采样表。

用来生成 skipgrams 的 sampling_table 参数。sampling_table[i] 是数据集中第 i 个最常见词的采样概率（出于平衡考虑，出现更频繁的词应该被更少地采样）。

``` python
keras.preprocessing.sequence.make_sampling_table(size, sampling_factor=1e-05)
```

### 文本预处理

#### Tokenizer

文本标记实用类。

该类允许使用两种方法向量化一个文本语料库： 将每个文本转化为一个整数序列（每个整数都是词典中标记的索引）； 或者将其转化为一个向量，其中每个标记的系数可以是二进制值、词频、TF-IDF权重等。

``` python
keras.preprocessing.text.Tokenizer(num_words=None, 
                                   filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', 
                                   lower=True, split=' ', 
                                   char_level=False, 
                                   oov_token=None)
```

#### hashing_trick

将文本转换为固定大小散列空间中的索引序列。

``` python
keras.preprocessing.text.hashing_trick(text, n, 
                                       hash_function=None, 
                                       filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', 
                                       lower=True, split=' ')
```

#### one_hot

One-hot 将文本编码为大小为 n 的单词索引列表。

``` python
keras.preprocessing.text.one_hot(text, n, 
                                 filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', 
                                 lower=True, split=' ')
```

#### text_to_word_sequence

将文本转换为单词（或标记）的序列。

``` python
keras.preprocessing.text.text_to_word_sequence(text, 
                                               filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', 
                                               lower=True, split=' ')
```

### 图像预处理

#### ImageDataGenerator 类

通过实时数据增强生成张量图像数据批次。数据将不断循环（按批次）。

``` python
keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, 
                                             samplewise_center=False, 
                                             featurewise_std_normalization=False, 
                                             samplewise_std_normalization=False, 
                                             zca_whitening=False, 
                                             zca_epsilon=1e-06, 
                                             rotation_range=0.0, 
                                             width_shift_range=0.0, 
                                             height_shift_range=0.0, 
                                             brightness_range=None, 
                                             shear_range=0.0, 
                                             zoom_range=0.0, 
                                             channel_shift_range=0.0, 
                                             fill_mode='nearest', 
                                             cval=0.0, 
                                             horizontal_flip=False, 
                                             vertical_flip=False, 
                                             rescale=None, 
                                             preprocessing_function=None, 
                                             data_format=None, 
                                             validation_split=0.0)
```

#### ImageDataGenerator 类方法

## 损失函数 Losses

### mean_squared_error
mean_squared_error(y_true, y_pred)

### mean_absolute_error
mean_absolute_error(y_true, y_pred)

### mean_absolute_percentage_error
mean_absolute_percentage_error(y_true, y_pred)

### mean_squared_logarithmic_error
mean_squared_logarithmic_error(y_true, y_pred)

### squared_hinge
squared_hinge(y_true, y_pred)

### hinge
hinge(y_true, y_pred)

### categorical_hinge
categorical_hinge(y_true, y_pred)

### logcosh
logcosh(y_true, y_pred)

### categorical_crossentropy
categorical_crossentropy(y_true, y_pred)

### sparse_categorical_crossentropy
sparse_categorical_crossentropy(y_true, y_pred)

### binary_crossentropy
binary_crossentropy(y_true, y_pred)

### kullback_leibler_divergence
kullback_leibler_divergence(y_true, y_pred)

### poisson
poisson(y_true, y_pred)

### cosine_proximity
cosine_proximity(y_true, y_pred)


## 评价函数 Metrics

### binary_accuracy

binary_accuracy(y_true, y_pred)

### categorical_accuracy

categorical_accuracy(y_true, y_pred)

### sparse_categorical_accuracy

sparse_categorical_accuracy(y_true, y_pred)

### top_k_categorical_accuracy

top_k_categorical_accuracy(y_true, y_pred, k=5)

### sparse_top_k_categorical_accuracy

sparse_top_k_categorical_accuracy(y_true, y_pred, k=5)

## 优化器 Optimizers

### SGD

随机梯度下降优化器

包含扩展功能的支持： - 动量（momentum）优化, - 学习率衰减（每次参数更新后） - Nestrov动量(NAG)优化

``` python
keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)
```

### RMSprop

RMSProp优化器.

建议使用优化器的默认参数 （除了学习率lr，它可以被自由调节）

这个优化器通常是训练循环神经网络RNN的不错选择。

``` python
keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)
```

### Adagrad

Adagrad优化器.

Adagrad是一种具有特定参数学习率的优化器，它根据参数在训练期间的更新频率进行自适应调整。 参数接收的更新越多，更新越小。

建议使用优化器的默认参数。

``` python
keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)
```

### Adadelta

Adadelta优化器.

Adadelta是Adagrad的一个具有更强鲁棒性的的扩展版本，它不是累积所有过去的梯度，而是根据渐变更新的移动窗口调整学习速率。 这样，即使进行了许多更新，Adadelta仍在继续学习。 与Adagrad相比，在Adadelta的原始版本中，您无需设置初始学习率。 在此版本中，与大多数其他Keras优化器一样，可以设置初始学习速率和衰减因子。

建议使用优化器的默认参数。

``` python
keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)
```

### Adam

Adam优化器.

默认参数遵循原论文中提供的值。

``` python
keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
```

### Adamax

Adamax优化器，来自Adam论文的第七小节.

它是Adam算法基于无穷范数（infinity norm）的变种。 默认参数遵循论文中提供的值。

``` python
keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)
```

### Nadam

Nesterov版本Adam优化器.

正像Adam本质上是RMSProp与动量momentum的结合， Nadam是采用Nesterov momentum版本的Adam优化器。

默认参数遵循论文中提供的值。 建议使用优化器的默认参数。

``` python
keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)
```

### TFOptimizer

原生Tensorlfow优化器的包装类（wrapper class）。

``` python
keras.optimizers.TFOptimizer(optimizer)
```

## 激活函数 Activations

### softmax

Softmax 激活函数。

``` python
softmax(x, axis=-1)
```

### elu

指数线性单元。

``` python
elu(x, alpha=1.0)
```

### selu

可伸缩的指数线性单元（SELU）。

``` python
selu(x)
```

### softplus

Softplus 激活函数。

``` python
softplus(x)
```

### softsign

Softsign 激活函数。

``` python
softsign(x)
```

### relu

线性修正单元。

``` python
relu(x, alpha=0.0, max_value=None)
```

### tanh

双曲正切激活函数。

``` python
tanh(x)
```

### sigmoid

Sigmoid 激活函数。

``` python
sigmoid(x)
```

### hard_sigmoid

Hard sigmoid 激活函数。

计算速度比 sigmoid 激活函数更快。

``` python
hard_sigmoid(x)
```

### linear

线性激活函数（即不做任何改变）

``` python
linear(x)
```

### 高级激活函数

## 回调函数 Callbacks

回调函数是一个函数的合集，会在训练的阶段中所使用。你可以使用回调函数来查看训练模型的内在状态和统计。你可以传递一个列表的回调函数（作为 callbacks 关键字参数）到 Sequential 或 Model 类型的 .fit() 方法。在训练时，相应的回调函数的方法就会被在各自的阶段被调用。

``` python
keras.callbacks.Callback()
```

### BaseLogger

会积累训练轮平均评估的回调函数。

这个回调函数被自动应用到每一个 Keras 模型上面。

``` python
keras.callbacks.BaseLogger()
```

### TerminateOnNaN

当遇到 NaN 损失会停止训练的回调函数。

``` python
keras.callbacks.TerminateOnNaN()
```

### ProgbarLogger

会把评估以标准输出打印的回调函数。

``` python
keras.callbacks.ProgbarLogger(count_mode='samples')
```

### History

把所有事件都记录到 History 对象的回调函数。

这个回调函数被自动启用到每一个 Keras 模型。History 对象会被模型的 fit 方法返回。

``` python
keras.callbacks.History()
```

### ModelCheckpoint

在每个训练期之后保存模型。

filepath 可以包括命名格式选项，可以由 epoch 的值和 logs 的键（由 on_epoch_end 参数传递）来填充。

``` python
keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)
```

### EarlyStopping

当被监测的数量不再提升，则停止训练。

``` python
keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')
```

### RemoteMonitor

将事件数据流到服务器的回调函数。

需要 requests 库。 事件被默认发送到 root + '/publish/epoch/end/'。 采用 HTTP POST ，其中的 data 参数是以 JSON 编码的事件数据字典。

``` python
keras.callbacks.RemoteMonitor(root='http://localhost:9000', path='/publish/epoch/end/', field='data', headers=None)
```

### LearningRateScheduler

学习速率定时器。

``` python
keras.callbacks.LearningRateScheduler(schedule, verbose=0)
```

### TensorBoard

Tensorboard 基本可视化。

TensorBoard 是由 Tensorflow 提供的一个可视化工具。

这个回调函数为 Tensorboard 编写一个日志， 这样你可以可视化测试和训练的标准评估的动态图像， 也可以可视化模型中不同层的激活值直方图。

``` python
keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)
```

### ReduceLROnPlateau

当标准评估已经停止时，降低学习速率。

当学习停止时，模型总是会受益于降低 2-10 倍的学习速率。 这个回调函数监测一个数据并且当这个数据在一定「有耐心」的训练轮之后还没有进步， 那么学习速率就会被降低。

``` python
keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)
```

### CSVLogger

把训练轮结果数据流到 csv 文件的回调函数。

支持所有可以被作为字符串表示的值，包括 1D 可迭代数据，例如，np.ndarray。

``` python
keras.callbacks.CSVLogger(filename, separator=',', append=False)
csv_logger = CSVLogger('training.log')
model.fit(X_train, Y_train, callbacks=[csv_logger])
```


### LambdaCallback

在训练进行中创建简单，自定义的回调函数的回调函数。

这个回调函数和匿名函数在合适的时间被创建。

``` python
keras.callbacks.LambdaCallback(on_epoch_begin=None, on_epoch_end=None, on_batch_begin=None, on_batch_end=None, on_train_begin=None, on_train_end=None)
```

## 模型可视化 Visulization

keras.utils.vis_utils模块提供了一些绘制Keras模型的实用功能(使用graphviz)。

以下实例，将绘制一张模型图，并保存为文件：

``` python
from keras.utils import plot_model
plot_model(model, to_file='model.png')
```

