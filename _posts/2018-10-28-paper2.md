---
layout: post
title: 【Paper】Responsibility for Crashes of Autonomous Vehicles - An Ethical Analysis
categories: Mobility
---

Hevelke A, Nida-Rümelin J. Responsibility for crashes of autonomous vehicles: an ethical analysis[J]. Science and engineering ethics, 2015, 21(3): 619-630.

## Motivation

A number of companies including Google and BMW are currently working on the development of autonomous cars. But if fully autonomous cars are going to drive on our roads, it must be decided who is to be held responsible in case of accidents. This involves not only legal questions, but also moral ones. The

## Research question

The first question discussed is whether we should try to design the tort liability for car manufacturers in a way that will help along the development and improvement of autonomous vehicles. In particular, Patrick Lin’s concern that any security gain derived from the introduction of autonomous cars would constitute a trade-off in human lives will be addressed.

The second question is whether it would be morally permissible to impose liability on the user based on a duty to pay attention to the road and traffic and to intervene when necessary to avoid accidents.

The last option discussed in this paper is a system in which a person using an autono- mous vehicle has no duty (and possibly no way) of interfering, but is still held (financially, not criminally) responsible for possible accidents. Two ways of doing so are discussed, but only one is judged morally feasible.


## Responsibility of the Manufacturer

The clearest answer is a practical one: if in the case of crashes involving autonomous vehicles the main responsibility were to be that of the manufacturers, ‘‘the liability burden on the manufacturer may be prohibitive of further development.’’ (Marchant and Lindor 2012).

Of course, full legislative protection from liability would probably also have undesirable effects: ‘‘it diminishes, if not eliminates, the incentives for manufacturers to make marginal improvements in the safety of their products in order to prevent liability.’’ (Marchant and Lindor 2012) Could a partial liability be designed in such a way that the continuous development and improvement of autonomous vehicles would not be impeded but promoted? It seems likely, but this question would have to be discussed and answered elsewhere. An ethical analysis would not solve it.

There is, on the other hand, the question of whether we should try to promote the development of autonomous cars to begin with. In other words: should we try to design the liability for autonomous vehicles in such a way that it promotes their continuous development and improvement? Should such vehicles be allowed on our streets? These questions can be addressed through normative ethics. If there are good moral reasons for finding the development and introduction of autonomous cars to be desirable, this can produce a moral obligation for the state to fashion the legal responsibility for crashes of autonomous cars in a way which helps the development and improvement of autonomous cars.

When we say autonomous cars can slash fatality rates by half, we really mean that they can save a net total of 16,000 lives a year: for example, saving 20,000 people but still being implicated in 4,000 new deaths. There’s something troubling about that, as is usually the case when there’s a sacrifice or ‘‘trading’’ of lives. The identities of many (future) fatality victims would change with the introduction of autonomous cars. 

some current non-victims—people who already exist—would become future victims, and this is clearly bad.’’ (Lin 2013).

A violation of some person’s fundamental rights cannot be legitimized on the basis of benefits for others, no matter how large. 

The introduction of autonomous vehicles is quite different from the paradigm of trolley-cases.5 In contrast to the standard trolley-case, we should not focus on the actual damage done in the end, when we try to determine if a decision in favour of autonomous vehicles is in the interest of one of the affected parties. Instead, the risks at the time of the decision should become central. Whether or not the introduction of a new safety feature is in the interest of a person does not depend on whether or not the person in question does have an accident in the end or how bad it may come to be. It depends on whether the feature improves his chances of avoiding the accident or reduce possible damage.

If that proves to be the case, it would certainly pose a problem. Otherwise, Lin’s concerns are unfounded.6 The introduction of autonomous cars would be no different (in this regard) to the introduction of already well-established safety features such as seatbelts or glued-in laminated windshields.

## A Duty to Intervene

The liability of the driver in the case of an accident would be based on his failure to pay attention and intervene. Autonomous vehicles would thereby lose much of their utility. It would not be possible to send the vehicle off to look for a parking place by itself or call for it when needed. One would not be able to send children to school with it, use it to get safely back home when drunk or take a nap while traveling. However, these matters are not of immediate ethical relevance. 

As long as there is some evidence that a system in which people must intervene would do noticeably better in terms of number of accidents than one in which autonomous vehicles are left to themselves there is much to be said in favour of such a duty.

But even assuming such intervention was possible, if the person in question were sufficiently focussed, one might still question if people would be able to keep up the necessary attention over longer periods of time.

However, if it becomes clear that humans are typically not able to effectively intervene when necessary to avert imminent accidents involving sophisticated autonomous vehicles, it becomes problematic to blame a person for an accident just because he did not – indeed could not prevent it. 

## Responsibility of the Driver as a Form of a ‘‘Strict Liability’’

One alternative would be an approach in which the person in charge of the autonomous vehicle has no duty (and possibly no way) of interfering, but still be considered morally responsible for possible accidents.

This would speak in favour of a system in which the cost of any accident caused by a (well-maintained, up to date, non-tampered-with etc.) autonomous vehicle is shared by all the owners/users of such vehicles.

This position is based on the assumption that it is possible to draw a clear line between the blameless driver and the (at least partly) guilty one.

For this very same reason we might blame a person using a sophisticated autonomous vehicle if it causes an accident-at least partly. He did decide to use a car, fully aware that he might hit another person, a child.

This means no driver could ever be ‘‘absolutely without fault’’ if his vehicle runs into another human being. It was a risk he knew about, a risk he took. Some sort of liability can always be morally justified when using dangerous vehicles like cars that have a chance of injuring others. Usually this might not be a major problem, but it is one for the Nagelian notions of moral luck, since according to him, bad luck is only morally irrelevant if the driver is ‘‘absolutely without fault’’—which he never is.

## Conclusion

We discussed who should be held responsible for accidents of fully autonomous cars from a moral stand point. Both the duty to intervene and a responsibility of the driver as a form of a ‘‘strict liability’’ seem like viable options.

In the case of a duty to intervene this depends on there being an actual chance for the driver to effectively anticipate and prevent accidents. If the average driver never had a real chance of preventing an accident (either in the particular case at hand or in principle) he should not be held responsible for it. Therefore this option seems more attractive to us as an interim solution for the period in which autonomous cars are first introduced and developed. Once the development of autonomous cars has reached a point where people cannot effectively intervene any more, a contra factual duty to do so would be morally indefensible. Also, a duty to intervene would keep autonomous cars from being useable by the blind, elderly, etc.

In the case of a responsibility of the driver as a form of a ‘‘strict liability’’, scenario (A) is the more viable one. It is justifiable to hold users of autonomous cars collectively responsible for any damage caused by such vehicles–even if they had no way of influencing the cars behaviour. However, this responsibility should not exceed a responsibility for the general risk taken by using the vehicle. A tax or a mandatory insurance seems the easiest and most practical means to achieve that. 

Assuming the implementation of autonomous cars would save lives, this by itself constitutes a powerful moral reason to limit the possible responsibilities of manufacturers to a point where it does not render the development of such cars too risky for the companies involved. Of course, manufacturers should not be freed of their liability in cases like the Ford Pinto, in which the manufacturers put the car on the market fully knowing that it had major safety defects, but considered rectifying those flaws too expensive. Also, a certain amount of responsibility for accidents not is only morally desirable in itself but also an important incentive for the continuous development and improvement of such cars.