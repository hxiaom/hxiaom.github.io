---
layout: post
title: 【Method】回归分析基础（四）多元线性回归：假设检验和置信区间
categories: Analytics
---

根据上一章的讨论，多元回归分析提供了一种减少遗漏变量偏差问题的方法，即在回归模型中增加解释变量从而控制这些解释变量的影响。多元回归模型的系数可通过OLS估计，由于不同样本下的估计量有所不同，因此和其他估计量一样，OLS估计量也具有抽样不确定性。

本章将利用标准误差、假设检验和置信区间等方法定量分析OLS估计量的抽样不确定性。与一元回归模型相比，多元回归中新出现的问题是同时涉及两个或多个回归系数的假设，检验这种“联合”假设需要用到一种新的检验统计量，即F统计量。

## 单个系数的假设检验和置信区间

本节将介绍多元回归模型中单个系数标准误差的计算、假设检验以及置信区间的构造方法。

### OLS估计量的标准误差

回顾一元回归的情形，我们用样本均值代替期望从而计算OLS估计量的方差，即$$\hat{\sigma}_{\hat{\beta}_1}^2$$。在最小二乘假设条件下，大数定理意味着样本均值收敛于其对应的总体均值，因此有$$\hat{\sigma}_{\hat{\beta}_1}^2 / \sigma_{\beta_1}^2 \to 1$$。\sigma}_{\hat{\beta}_1}^2的平方根即为$$\hat{\beta}_1$$的标准误差$$SE(\hat{\beta}_1)$$，而$$SE(\hat{\beta}_1)$$正是$$\hat{\beta}_1$$的标准差的估计量。

上述结论都可以直接推广到多元回归中。第j个回归系数的OLS估计量$$\hat{\beta}_j$$的标准差可用其标准误差$$SE(\hat{\beta}_j)$$来估计，利用矩阵很容易得到该标准误差的表达式。需要注意的是，一元回归和多元回归的标准误差在概念上并没有区别。OLS估计量的核心思想是，无论回归中有一个、两个还是多个解释变量，估计量在大样本条件下的正态性和标准差估计量的一致性都不会改变。

### 单个系数的假设检验

我们可能想要检验第j个解释变量系数$$\beta_j$$的真值等于某个特定值（如$$\beta_{j,0}$$）。其中，原假设的取值$$\beta_{j,0}$$或来自经济理论，或者来自实际应用的决策问题。如果备择假设是双边的，则这两个假设的数学表述为

$$H_0: \beta_j = \beta_{j,0}; H_1: \beta_j \neq \beta_{j,0}$$

(1) 计算$$\hat{\beta}_j$$的标准误差$$SE(\hat{\beta}_j)$$

(2) 计算t统计量

$$t = \frac{\hat{\beta}_j - \beta_{j,0}}{SE(\hat{\beta}_j)}$$

(3) 计算p值

$$p-value = 2 \phi (- \mid t^{act} \mid)$$

其中$$t^{act}$$为实际计算的t统计量的值。当p值小于0.05，或等价地，$$\mid t^{act} \mid > 1.96$$时，在5%的显著性水平下拒绝原假设。

回归软件一般会自动计算标准误差、t统计量和p值。

### 单个系数的置信区间

多元回归模型中构造置信区间的方法与一元回归模型相同。

在控制其他解释变量不变的情况下，系数$$\beta_j$$的95%双边置信区间表示该区间包含$$\beta_j$$真值的概率为95%，即在所有可能的随机样本构造的置信区间中有95%包含了$$\beta_j$$的真值。等价地，它是在5%的显著性水平下，双边假设检验不能拒绝的$$\beta_j$$的取值集合。当样本容量足够大时，95%置信区间为

$$\beta_j的95%置信区间 = [\hat{\beta}_j - 1.96SE(\hat{\beta}_j), \hat{\beta}_j + 1.96SE(\hat{\beta}_j)]$$

上述置信区间的构造方法都依赖于OLS估计量$$\hat{\beta}_j$$在大样本下的渐近正态性。因此，这些量化抽样不确定性的方法只有在大样本下才能使用。

## 联合假设的检验

本节将介绍多元回归系数的联合假设的表述及检验所用的F统计量。

### 两个或多个系数的假设检验

联合原假设。一般来说，联合假设（joint hypothesis）是指对回归系数施加两个或两个以上约束的假设。考虑如下形式的联合原假设和备择假设：

$$H_0: \beta_j = \beta_{j,0}, \beta_m = \beta_{m,0}, ..., 共q个约束$$

$$H_1: H_0的q个约束中至少有一个不成立$$

式中，$$\beta_j, \beta_m, ...$$表示不同的回归系数，$$\beta_{j,0}, \beta_{m,0}, ...$$表示原假设下这些系数的取值。

为什么不能逐个检验系数？虽然看似可以利用常用的t统计量逐个检验每个约束从而检验联合假设，但下述计算表明这种方法并不靠谱。具体地，假设你对联合假设$$\beta_1 = 0 且\beta_2 = 0$$感兴趣，令$$t_1$$表示检验原假设$$\beta_1=0$$的t统计量，$$t_2$$表示检验原假设$$\beta_2=0$$的t统计量。若逐个检验，当$$t_1$$或$$t_2$$的绝对值超过1.96时拒绝联合原假设，将会怎样？

由于这个问题涉及两个随机变量$$t_1$$和$$t_2$$，其解答需要知道$$t_1$$和$$t_2$$的联合抽样分布。在大样本下$$\hat{\beta}_1$$和$$\hat{\beta}_2$$服从联合正态分布，因此在联合原假设下，t统计量$$t_1$$和$$t_2$$服从二维正态分布，其中每个t统计量的均值为零且方差为1。

首先考虑两个t统计量不相关，即相互独立的情况。逐个检验时检验的水平是多少即当原假设为真时，拒绝原假设的概率为多少？超过5%！在这种特殊情况下，我们可以准确计算出这种方法的拒绝概率。只有当$$\mid t_1 \mid \leq 1.96$$且$$\mid t_2 \mid \leq 1.96$$时不能拒绝原假设，又由于t统计量相互独立，则$$P(\mid t_1 \mid \leq 1.96且\mid t_2 \mid \leq 1.96) = P(\mid t_1 \mid \leq 1.96) \times P(\mid t_2 \mid \leq 1.96) = 0.95^2 = 90.25%$$，所以当原假设为真时，拒绝原假设的概率为$$1-0.95^2 = 9.75%$$。这种逐个检验的方法增加了拒绝原假设的机会，当第一个t统计量无法拒绝原假设时，还可以尝试第二个t统计量，从而非常容易拒绝原假设。

如果解释变量相关，则情况将更加复杂。逐个检验方法的显著性水平取决于解释变量间的相关系数。由于逐个检验方法的检验水平存在问题，即原假设为真时的拒绝概率不等于合意的显著性水平，因此我们需要采用新的方法。

一种途径是改进逐个检验的方法，使其采用不同的临界值以确保总显著性水平等于合意的显著性水平，这种方法称为Bonferroni方法。其优点是应用广泛，缺点是检验的势较低，即在备择假设实际上位真的，它经常无法拒绝原假设。

幸运的是，还有一种更为有效的，特别是解释变量高度相关时检验联合假设的方法，即基于F统计量的检验方法。

### F统计量

F统计量（F-statistic）可用于检验回归系数的联合假设。现代回归软件中都编入了F统计量的公式。我们先讨论两个约束条件的情形，然后再推广到q个约束的一般情形。

两个约束的F统计量。当联合原假设具有两个约束$$\beta_1=0$$和$$\beta_2=0$$时，F统计量通过下述公式将两个t统计量$$t_1$$和$$t_2$$联系在一起：

$$F  =\frac{1}{2}(\frac{t_1^2 + t_2^2 - 2 \hat{\rhe}_{t_1, t_2} t_1 t_2}{1- \hat{\rhe}_{t_1, t_2}^2})$$

式中，$$\hat{\rhe}_{t_1, t_2}$$为两个t统计量间相关系数的估计量。

为了理解上式中的F统计量，首先假定我们已知t统计量不相关，因而可以去掉包含$$\hat{\rhe}_{t_1, t_2}$$的项，此时上式化简为$$F=\frac{1}{2}(t_1^2 + t_2^2)$$，即F统计量为t统计量平方和的均值。在原假设下，$$t_1$$和$$t_2$$是相互独立的标准正态随机变量（因为我们已假设t统计量之间不相关），F统计量服从$$F_{2,\infty}$$分布。在$$\beta_1$$非零或$$\beta_2$$非零（或二者均非零）的备择假设下，若$$t_1^2$$或$$t_2^2$$（或二者）很大将导致检验拒绝原假设。

一般情况下，t统计量之间是相关的，F统计量的公式修正了这种相关性。通过该修正使得在原假设下，无论t统计量是否相关，F统计量在大样本下都服从$$F_{2,\infty}$$分布。

q个约束的F统计量。在原假设下，F统计量在大样本情况下服从$$F_{q,\infty}$$分布，即在大样本下，当原假设成立时，有

$$F统计量服从F_{q,\infty}分布$$

因此，对特定的q和所需的显著性水平，可以从$$F_{q,\infty}$$分布表中查到F统计量的临界值。

利用统计软件计算异方差-稳健的F统计量。如果用异方差-稳健标准误差计算F统计量，则无论误差项是同方差还是异方差，原假设成立和大样本条件下F统计量都服从$$F_{q,\infty}$$。大多数统计软件都默认计算同方差适用的标准误差，因此在某些软件包中你必须选择“稳健”的选项才会利用异方差-稳健的标准误差（或者更一般地，“协方差矩阵”的异方差-稳健估计值）计算F统计量。

利用F统计量计算p值。利用$$F_{q,\infty}$$分布信息可计算F统计量的p值。令$$F^{act}$$代表实际计算得到的F统计量，由于原假设成立条件下F统计量在大样本时服从$$F_{q,\infty}$$分布，因此p值为

$$p-value = P[F_{q,\infty} > F^{act}]$$

