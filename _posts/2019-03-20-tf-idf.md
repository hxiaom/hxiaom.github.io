---
layout: post
title: 【Daily Method】TF-IDF
categories: Analytics
---

## 目的

词语相对于文章的重要性指标。

常用于：
- 文章中关键词获取；
- 文章中词语重要性加权；
- 检索结果排序
    - TF-IDF用于检索的核心思想是把“查询串q和文档d的匹配度问题”转化为“查询串q来自于文档d的条件概率问题”。IDF虽然对于每个网页是一样的，但是他用于调节多个检索词的重要性权重。
    - 此时，TF看作document term weight，IDF看作query term weight


## 原理

前提：
1. 有个语料库，语料库里有多个文件；
2. 每个文件包含多个词语。

原理：
1. 字词的重要性随着它在文件中出现的次数成正比增加；（TF计算）
2. 但同时会随着它在语料库中出现的频率成反比下降。（IDF计算）
3. TF-IDF = TF * IDF （同时考虑TF与IDF）

本质上IDF是一种试图抑制噪音的加权，并且单纯地认为文本频数小的单词就越重要，文本频数大的单词就越无用，显然这并不是完全正确的。IDF的简单结构并不能有效地反映单词的重要程度和特征词的分布情况，使其无法很好地完成对权值调整的功能，所以TFIDF法的精度并不是很高。因此有时候TF-IDF，并不一定比单纯的TF有效。

IDF被看作是 $$ -log P(t \mid d) $$, 其中$$ P(t \mid d) $$ 是给定一个文章d，其包含词语t的概率。通过统一到概率论，来理论化TF-IDF。然而这种方法用于解释词语的相对重要性是好的，但用于解释检索排序，则又需要将检索词的概率囊括进来，出现了新的问题。



## 计算

### Term Frequency(TF)
TF有很多不同的算法，从简单到复杂。但目的都是反映该词语在文章中的出现频次。

| Weighting Scheme | TF Weight |
| ---------------- | --------- |
| binary           | 0,1       |
| raw count        | $$f_{t,d}$$ | 
| term frequency   | $$\frac {f_{t,d}}{\sum_{t' \in d} f_{t',d}}$$  |
| log normalization | $$ log(1+ f_{t,d}) $$ |
| double normalization 0.5 | $$ 0.5 + 0.5 * \frac {f_{t,d}}{\max_{t' \in d} f_{t',d}}$$ |
| double normalization K | $$ K + (1-K)\frac {f_{t,d}}{\max_{t' \in d} f_{t',d}} $$ |


### Inverse document frequency(IDF)
IDF也有很多不同的算法，但目的都是反映该词语在语料库中出行的频次的**倒数**。这个指数衡量的是这个单词包含了多少信息。

| Weighting Scheme | IDF Weight $$ (n_t = \mid d \in D : t \in d \mid) $$ |
| ---------------- | ---------------- |
| unary            | 1                |
| inverse document frequency | $$ log\frac {N}{n_t} = -log \frac{n_t}{N} $$ |
| inverse document frequency smooth | $$ log(\frac {N}{1+n_t}) $$ |
| inverse document frequency max    | $$ log(\frac {\max_{t' \in d} n_{t'}}{1+n_t}) $$ |
| probabilistic inverse document frequency | $$ log \frac {N-n_t}{n_t} $$ |

### TF-IDF

Recommended tf–idf weighting schemes

| weighting sheme | document term weight | query term weight |
| --------------- | -------------------- | ----------------- |
| 1 | $$ f_{t,d}*log \frac {N}{n_t} $$ | $$ (0.5 + 0.5 * \frac {f_{t,d}}{\max_{t' \in d} f_{t',d}})* log \frac {N}{n_t} $$  |
| 2 | $$ 1+log(f_{t,d}) $$ | $$ log(1+\frac {N}{n_t}) $$ |
| 3 | $$ (1+log(f_{t,d}))*log \frac {N}{n_t} $$ | $$ (1+log(f_{t,q}))*log \frac {N}{n_t} $$ |


## 现成的包

- [NLTK + scikit-learn](https://www.bogotobogo.com/python/NLTK/tf_idf_with_scikit-learn_NLTK.php)

## 使用TF-IDF的文献

Zhu, Li, Fei Richard Yu, Yige Wang, Bin Ning, and Tao Tang. “Big Data Analytics in Intelligent Transportation Systems : A Survey.” IEEE Transactions on Intelligent Transportation Systems 20, no. 1 (2019): 383–98. doi:10.1109/TITS.2018.2815678.

## 参考文献
1. [wikipedia: tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)

