---
layout: post
title: 【Method】SVM (六) 调参及优缺点
categories: Analytics
---

## 原理

### 核函数选择

n = 特征数, m = 训练样本数

Linear kernel: 如果 n 相对于 m 很大。例如 n >> m, n=10,000, m=10~1000

Gaussian kernel: n较小，m中等。 n=1~1000, m=10~10,000

Linear kernel: n较小，m很大。n=1~1000, m>50,000

### 调参

gamma 越大，支持向量越少，gamma 越小，支持向量越多。而支持向量的个数影响训练和预测的速度。 

C 越高，容易过拟合。C 越小，容易欠拟合。


## 优点

- SVM 是一种有坚实理论基础的新颖的小样本学习方法。 
- SVM 的最终决策函数只由少数的支持向量所确定,计算的复杂性取决于支持向量的数目,而不是样本空间的维数,这在某种意义上避免了“维数灾难”。

## 缺点：

- SVM算法对大规模训练样本难以实施。

## 参考资料

- [吴恩达机器学习之svm根据训练样本数量和样本特征数量关系选择核函数](https://blog.csdn.net/daixiangzi/article/details/80904960)
- [SVM 的核函数选择和调参](https://blog.csdn.net/aliceyangxi1987/article/details/80617649)
- [SVM 调参策略](https://blog.csdn.net/u014484783/article/details/78220646)