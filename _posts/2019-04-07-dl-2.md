---
layout: post
title: 【Method】深度学习（二）代价函数
categories: Analytics
---

## 原理 

设计和训练神经网络与使用梯度下降训练其他任何机器学习模型并没有太大不同。

我们到目前为止看到的线性模型和神经网络最大的区别，在于神经网络的非线性性导致大多数我们感兴趣的代价函数都变得非凸。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或SVM的凸优化算法那样保证全局收敛。凸优化从任何一种初始参数出发都会收敛（理论上如此——在实践中也很鲁棒但可能会遇到数值问题。）用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。对于前馈神经网络，将所有的权重值初始化为小随机数是很重要的。偏置可以初始化为零或者小的正值。

训练算法几乎总是基于使用梯度来使得代价函数下降的各种方法。一些特别的算法是对梯度下降思想的改进和提纯。还有一些更特别的，大多数是对随机梯度下降算法的改进。

我们当然也可以用梯度下降来训练诸如线性回归和支持向量机之类的模型，并且事实上当训练集相当大时这是很常用的。从这点来看，训练神经网络和训练其他任何模型并没有太大区别。计算梯度对于神经网络会略微复杂一些，但仍然可以很高效而精确地实现。之后我们将会介绍如何用反向传播算法以及它的现代扩展算法来求得梯度。

和其他机器学习模型一样，为了使用基于梯度的学习方法我们必须选择一个代价函数，并且我们必须选择如何表示模型的输出。

### 代价函数

深度神经网络设计中的一个重要方面是代价函数的选择。幸运的是，神经网络的代价函数或多或少是和其他的参数模型例如线性模型的代价函数相同的。

在大多数情况下，我们的参数模型定义了一个分布$$p(y \mid x; \theta)$$并且我们简单地使用最大似然原理。这意味着我们使用训练数据和模型预测间的交叉熵作为代价函数。

有时，我们使用一个更简单的方法，不是预测y的完整概率分布，而是仅仅预测在给定x的条件下y的某种统计量。某些专门的损失函数允许我们来训练这些估计量的预测器。

用于训练神经网络的完整的代价函数，通常在我们这里描述的基本代价函数的基础上结合一个正则项。用于线性模型的权值衰减方法也直接适用于深度神经网络，而且是最流行的正则化策略之一。

#### 使用最大似然学习条件分布

大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价。这个代价函数表示为

$$J(\theta) = -E_{x,y \sim \hat{p}_data} (y \mid x)$$

代价函数的具体形式随着模型而改变，取决于$$log p_{model}$$的具体形式。上述方程的展开形式通常会有一些项不依赖于模型的参数，我们可以舍去。例如，如果$$p_{model} (y \mid x) = N(y;f(x; \theta), I)$$，那么我们就重新得到了均方误差代价，

$$J(\theta) = \frac{1}{2} E_{w,y \sim \hat{p}_{data}} \| y -f(x;\theta) \|^2 + const$$

至少系数$$\frac{1}{2}$$和常数项不依赖于$$\theta$$。舍弃的常数是基于高斯分布的方差，在这种情况下我们选择不把它参数化。之前，我们看到了对输出分布的最大似然估计和对线性模型均方误差的最小化之间的等价性，但事实上，这种等价性并不要求$$f(x;\theta)$$用于预测高斯分布的均值。

使用最大似然来导出代价函数的方法的一个优势是，它减轻了为每个模型设计代价函数的负担。明确一个模型$$p(y \mid x)$$则自动地确定了一个代价函数$$log p(y \mid x)$$。

贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的大和具有足够的预测性，来为学习算法提供一个好的指引。饱和（变得非常平）的函数破坏了这一目标，因为它们把梯度变得非常小。这在很多情况下都会发生，因为用于产生隐藏单元或输出单元的输出的激活函数会饱和。负的对数似然帮助我们在很多模型中避免这个问题。很多输出单元都会包含一个指数函数，这在它的变量取绝对值非常大的负值时会造成饱和。负对数似然代价函数中的对数函数消除了某些输出单元中的指数效果。

用于实现最大似然估计的交叉熵代价函数有一个不同寻常的特性，那就是当它被应用于实践中经常遇到的模型时，它通常没有最小值。对于离散型输出变量，大多数模型以一种特殊的形式来参数化，即它们不能表示概率零和一，但是可以无限接近。逻辑回归是其中一个例子。对于实值的输出变量，如果模型可以控制输出分布的密度（例如，通过学习高斯输出分布的方差参数），那么它可能对正确的训练集输出赋予极其高的密度，这将导致交叉熵趋向于负无穷。之后描述的正则化技术提供了一些不同的方法来修正学习问题，使得模型不会通过这种方式来获得无限制的收益。

#### 学习条件统计量

有时我们并不是想学习一个完整的概率分布$$p(y \mid x; \theta)$$，而仅仅是想学习在给定x时y的某个条件统计量。

例如，我们可能有一个预测期$$f(x;\theta)$$，我们想用它来预测y的均值。如果我们使用一个足够强大的神经网络，我们可以认为这个神经网络能够表示一大类函数中的任何一个函数f，这个类仅仅被一些特征所限制，例如连续性和有界，而不是具有特殊的参数形式。从这个角度来看，我们可以把代价函数看作是一个泛函数（functional）而不仅仅是一个函数。泛函是函数到实数的映射。我们因此可以将学习看作是选择一个函数而不仅仅是选择一组参数。我们可以设计代价泛函在我们想要的某些特殊函数处取得最小值。例如，我们可以设计一个代价泛函，使它的最小值处于一个特殊的函数上，这个函数将x映射到给定x时y的期望值。对函数求解优化问题需要用到变分法（calculus of variations）这个数学工具。目前，只需要知道变分法可以被用来导出下面的两个结果。

我们使用变分法导出的第一个结果是解优化问题

$$f^* = arg min_f E_{x,y \sim P_{data}} \| y -f(x) \|^2$$

得到

$$f^*(x) = E_{y \sim P_{data} (y \mid x)} [y]$$

要求这个函数在我们要优化的类里。换句话说，如果我们能够用无穷多的、来源真实的数据生成分布的样本进行训练，最小化均方误差代价函数将得到一个函数，它可以用来对每个x的值预测出y的均值。

不同的代价函数给出不同的统计量。第二个使用变分法得到的结果是

$$f^* = arg min_f E_{x,y \sim P_{data}} \| y -f(x) \|_1$$

将得到一个函数可以对每个x预测y取值的中位数，只要这个函数在我们要优化的函数族内。这个代价函数通常被称为平均绝对误差（mean absolute error）。

可惜的是，均方误差和平均绝对误差在使用基于梯度的优化方法时，往往成效不佳。一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度。这就是交叉熵代价函数比均分误差或者平均绝对误差更受欢迎的原因之一了，即使是在没有必要估计整个$$p(y \mid x)$$分布时。