---
layout: post
title: 【Method】回归分析基础（六）多元回归分析有效性的评估
categories: Analytics
---

本章将研究多元回归分析在什么情况下是可靠的，而在什么情况下是不可靠的。我们将集中讨论旨在估计解释变量变化对被解释变量的因果效应的统计分析，我们要了解多元回归分析给出的因果效应估计在什么情况下是有效的，什么情况下是无效的。

本章将介绍评估统计有效性的一般框架，这一框架适用于回归分析，也适用于其他分析。该框架是建立在内部有效性和外部有效性的概念基础上。如果某项研究关于因果效应的统计推断对所研究的总体及环境是有效的，则称其具有内部有效性；如果某项研究的统计推断可以推广到其他总体及环境中，则称其具有外部有效性。

## 内部有效性和外部有效性

如果某项研究关于因果关系的统计推断对所研究的总体是有效的，则称其具有内部有效性（internal validity）。如果统计推断及结论可以推广到其他总体及环境中，则称其具有外部有效性（external validity）。

内部有效性和外部有效性将我们所研究的总体及环境与（欲将研究结论推广到）其他总体及环境做了区分。其中，研究的总体（population studied）是指从中抽样的个人、公司或学区等总体。结论可推广到其他总体，或感兴趣的总体（population of interest），即我们意将研究所得到的因果推断推广到的总体。例如，某中学（9~12年级）校长想把我们关于加利福利亚小学学区（研究总体）班级规模和测试成绩的结论推广到中学总体（感兴趣的总体）中。

这里的“环境”是指制度、法律、社会和经济环境。例如，在实验室内评估的有机番茄种植方法的结论能否推广到田间，即在实验室环境中有效的有机种植方法能否在现实世界环境中发挥同样的效果，了解这一点是很重要的。

### 内部有效性的威胁

内部有效性由两部分组成。第一，因果效应的估计量应该是无偏和一致的。

第二，假设检验应该具有合意的显著性水平（在原假设下，被拒绝的实际概率应该等于合意的显著性水平），置信区间也应该具有合意的置信水平。

在回归分析中，因果效应是通过估计回归函数得到的，而假设检验是基于估计的回归系数及其标准误差来进行的。相应地，在基于OLS回归的研究中，内部有效性要求OLS估计量是无偏和一致的，同时要求计算的标准误差要使置信区间具有合意的置信水平。然而，存在各种各样的原因会使上述条件无法成立，这些原因便构成了内部有效性的威胁。这些威胁导致一个或多个最小二乘条件不成立。例如，我们详细讨论过的遗漏变量偏差问题就是一个威胁，它会导致一个或多个回归变量与误差项相关，从而违背了第一个最小二乘假设。如果能够获得遗漏变量或控制变量的数据，则我们可以通过在回归中加入这些变量从而避免遗漏变量偏差带来的威胁。

### 外部有效性的威胁

外部有效性的潜在威胁来自研究总体及环境和感兴趣的总体及环境之间的差异。

总体间的差异。研究总体和感兴趣的总体之间的差异构成了外部有效性的威胁。例如，实验室中通常利用像老鼠这样的动物总体（研究总体）来研究化学药品的毒性，但其结果却被用来制定人类（感兴趣的总体）的健康和安全准则。老鼠和人类之间的差异是否足够大，以致威胁到此类研究的外部有效性，这仍存在争议。

一般而言，研究总体的真实因果效应与感兴趣的总体的真实因果效应可能不同，这可能是因为所研究总体的选取方法使其与感兴趣的总体出现差异，或因为总体特征不同，或因为地理位置不同，又或是因为研究已经过时。

环境的差异。即使研究总体和感兴趣的总体完全相同，但如果环境存在差异，也可能无法推广研究结果。例如，如果两所大学对酗酒的惩罚措施不同，即使两所大学的学生总体相同，也不能将其中一所大学的反酗酒宣传活动对大学生酗酒的效应推广到另一所大学。在这个例子中，研究所处的法律环境与研究结论欲推广到的法律环境是不同的。

一般而言，环境差异的例子包括制度环境的差异（如公立大学和宗教大学）、法律的差异（如法律制裁的差异）或自然环境的差异。

感兴趣的总体及环境与研究总体及环境越接近，则越可能具有外部有效性。

如何评估一项研究的外部有效性。外部有效性评估必须借助对研究总体及环境和感兴趣的总体及环境的具体了解。如果二者之间存在显著差异，则研究的外部有效性就值得怀疑。

有时，围绕不同但相关的总体会存在两个或多个相似研究。如果是这样的话，我们可以通过比较两个研究结果来检验它们的外部有效性。一般来说，两个或多个研究结论相似，则支持外部有效性，但如果这些结论存在无法解释的差异，则我们有理由怀疑其外部有效性。

如何设计具有外部有效性的研究。由于外部有效性的威胁来源于总体及环境缺乏可比性，所以最好在收集数据之前，即研究初期就尽量降低这些威胁。

## 多元回归分析的内部有效性威胁

本节将讨论造成多元回归系数的OLS估计量在大样本下仍然有偏的五个原因，即遗漏变量、回归函数形式的误设、解释变量测量偏误（“变量误差”）、样本选取及双向因果关系。这五个偏差产生的原因都是由于回归模型中解释变量与误差项相关，从而违背了第一个最小二乘假设。这里将针对每一个原因讨论如何缩小偏差，本节最后将讨论导致标准误差非一致的情况及其处理办法。

### 遗漏变量偏差

由之前的讨论可知，如果回归中遗漏了某个影响Y且与一个或多个解释变量相关的变量时，就会产生遗漏变量偏差。即使在大样本下，这一偏差仍然存在，故OLS估计量是非一致的。如何尽量减少遗漏变量偏差，则取决于我们是否能够获得潜在遗漏变量的数据。

当遗漏变量可观测或有足够的控制变量时，遗漏变量偏差的解决方法。如果你有遗漏变量的数据，那么在多元回归模型中加入该变量便可解决遗漏变量偏差问题。或者，如果你有一个或多个控制变量的数据，且这些控制变量是足够的，即能够保证条件均值独立假设成立，则加入这些控制变量便可消除感兴趣变量系数的潜在偏差。

在回归中加入新的变量由好处也有坏处。一方面，遗漏变量可能导致遗漏变量偏差；另一方面，如果加入了不该回归的变量（即其总体回归系数为零），则会降低其他回归系数估计量的精确度。换句话说，是否要加入该变量取决于感兴趣系数估计量的偏差和方差之间的权衡。在实际应用中，以下四个步骤可以帮助你决定在回归中是否应该加入某个或多个变量。

第一步：确定回归中的主要系数或感兴趣的系数。在测试成绩的回归中，由于一开始提出的问题是关于降低学生-教师比对测试成绩产生的影响，所以学生-教师比的系数是我们感兴趣的系数。

第二步：考虑该回归中的遗漏变量偏差最可能来源于哪里？回答这一问题需要运用经济理论和专业知识，而且应该在建立回归之前就加以考虑。由于这一步是在分析数据之前进行的，故也称之为先验（“事实之前”）推理。在测试成绩的例子中，这一步要求确定测试成绩的决定因素，如果忽略这些因素会导致班级规模效应估计量有偏。由此，我们可以得到回归的基本设定形式，这也是实证分析的出发点，同时也得到了有助于减少遗漏变量偏差的“可疑”变量。

第三步：利用第二步中确定的可疑控制变量扩展基本设定形式。如果新加入的控制变量系数统计上显著，或当加入这些变量后感兴趣的系数估计值明显改变，则回归中应该保留这些变量，于是需要修改基本设定形式。反之，则应该在回归中去掉这些变量。

第四步：以列表形式给出你的详细估计结果，为持有怀疑精神的读者“充分揭示”你所掌握的信息，以便于他们可以从中去推导自己关心的结论。

当有效控制变量不可观测时，遗漏变量偏差的解决办法。如果你没有关于遗漏变量或其他有效控制变量的数据，则在回归中加入这些变量的方法就不可行。尽管如此，还是有三种解决遗漏变量偏差的方法。这三种方法都是通过采用不同类型的数据来避免遗漏变量偏差。

第一种方法是利用同一组个体在不同时间点的观测数据。例如，我们收集到了两组数据，分别是同一学区在1995年和2000年的测试成绩和相关变量的数据。这种形式的数据称为面板数据。只要这些遗漏变量不随时间而变化，则利用面板数据就可以控制这些不可观测的遗漏变量。

第二种方法是利用工具变量回归。该方法依赖于一个称为工具变量的新变量。

第三章方法是利用研究设计，即利用随机对照实验去分析感兴趣的效应（如缩小班级规模对学生测试成绩的影响）。

### 回归函数形式的误设

如果真实的回归函数是非线性的，但我们估计的却是线性回归模型，则这种函数形式误差（functional form misspecification）将会导致OLS估计量有偏。 这种偏差也是一种遗漏变量偏差，其中的遗漏变量是指能反映回归函数中缺少的非线性部分的信息的变量。例如，如果真实的回归函数为二次多项式，则在回归中遗漏解释变量的二次项将会导致遗漏变量偏差。

函数形式误设的解决方法。当被解释变量连续时（如测试成绩），可以利用非线性模型的方法解决这种潜在的非线性问题。然而，如果被解释变量是离散的或二元的，则情况会变得更复杂。我们将在后续章节讨论离散型被解释变量的回归。

### 测量误差和变量的测量偏误

假设在测试成绩对学生-教师比的回归中，我们不小心弄混了数据，得到了学区内五年级的测试成绩对十年级的学生-教师比的回归。虽然五年级的学生-教师比和十年级的学生-教师比相关，但它们仍是不同的，故这一混淆会导致系数估计量的有偏性。由于这种偏差来源于解释变量的测量误差，所以称其为变量的测量偏误（errors-in-variable bias）。即使在大样本下这一偏差仍然存在，所以当存在测量误差时，OLS估计量是非一致的。

导致测量误差的原因有很多。如果数据是通过调查得到的，则受访者给出的答案可能并不真实。例如，《当前人口调查》中有一个问题是关于去年的收入，某受访者可能不知道他的确切收入或由于其他原因而没有正确回答。另外，如果数据来源于官方电子记录，也可能存在数据首次输入时的录入错误。

为了了解变量的测量误差如何导致解释变量与误差项相关，我们假设回归中只有一个解释变量$$X_i$$（如实际收入），但其被误测为$$\tilde{X}_i$$（受访者给出的收入）。由于观测到的是$$\tilde{X}_i$$而不是$$X_i$$，所以回归方程实际上是基于$$\tilde{X}_i$$估计得到的。用误测的变量$$\tilde{X}_i$$表示总体回归方程$$Y_i=\beta_0 + \beta_1 X_i + u_i$$，得到

$$Y_i = \beta_0 + \beta_1 \tilde{X}_i + [\beta_1(X_i - \tilde{X}_i) + u_i] = \beta_0 + \beta_1 \tilde{X}_i + v_i$$

其中，$$v_i = \beta_1 (X_i - \tilde{X}_i) + u_i$$。因此，用$$\tilde{X}_i$$作为解释变量的回归方程的误差项中包含了测量误差，即$$\tilde{X}_i$$与$$X_i$$的差值。如果这个差值与误测值$$\tilde{X}_i$$相关，则回归变量$$\tilde{X}_i$$与误差项相关，从而$$\hat{\beta}_1$$是有偏且非一致的。

$$\hat{\beta}_1$$偏差的大小及符号取决于$$\tilde{X}_i$$与测量误差$$\tilde{X}_i - X_i$$的相关系数，而这个相关系数又取决于测量误差的具体性质。

例如，我们假设误测值$$\tilde{X}_i$$等于无法测量的真实值$$X_i$$加上一个纯粹的随机成分$$w_i$$，其中$$w_i$$均值为零，方差为$$\sigma_w^2$$。因为该误差是纯随机的，所以我们可以假设$$w_i$$与$$X_i$$及回归误差项$$u_i$$都不相关。这一假设构成了经典测量误差模型（classical measurement error model），其中$$\tilde{X}_i = X_i + w_i$$，且$$corr(w_i, X_i) = 0, corr(w_i, u_i)=0$$。在经典测量误差模型中，由简单的代数运算即可证明$$\hat{\beta}_1$$的概率极限为

$$\hat{\beta}_1 \to \frac{\sigma_X^2}{\sigma_X^2 + \sigma_w^2} \beta_1$$

即如果测量误差的效果等同于在解释变量真实值中加入一个随机要素，则$$\hat{\beta}_1$$是非一致的。由于$$\frac{\sigma_X^2}{\sigma_X^2 + \sigma_w^2} <1$$，则$$\hat{\beta}_1$$即使在大样本下也偏向于零。在极端情况下，测量误差大到几乎不包含$$X_i$$的信息，则上式中方差之比为零，即$$\hat{\beta}_1$$依概率收敛至零。在另一种极端情况下，即当不存在测量误差时，$$\sigma_w^2=0$$，从而$$\hat{\beta}_1 \to \beta_1$$。

测量误差的另一种模型是假设受访者给出了他对于真实值的最佳估计值。在这种“最佳猜测”模型中，给定可获得的受访者相关信息时，得到的$$\tilde{X}_i$$被设定为$$X_i$$的条件均值。因为$$\tilde{X}_i$$是最佳估计，故测量误差$$\tilde{X}_i - X_i$$与$$\tilde{X}_i$$不相关（如果测量误差与$$\tilde{X}_i$$相关，这种相关性会为预测$$X_i$$提供有用的信息，故$$\tilde{X}_i$$就不是$$X_i$$的最佳猜测了），即$$E[(\tilde{X}_i - X_i)\tilde{X}_i]=0$$，且如果受访者的个人信息与$$u_i$$不相关，则$$\tilde{X}_i$$与误差项$$v_i$$也不相关。因此，在“最佳猜测”测量误差模型中，$$\hat{\beta}_1$$是一致的，但由于$$Var(v_i) > Var(u_i)$$，故$$\hat{beta}_1$$的方差要大于不存在测量误差时的方差。

如果存在刻意误报的情况，则测量误差导致的问题将更加复杂。例如，在调查中假设受访者刻意少报了真实的应纳税收入，如没有包含现金支付。如果每个受访者都只给出其90%的收入，则$$\tilde{X}_i=0.9X_i$$，从而$$\hat{\beta}_1$$将存在10%的向上偏差。

尽管上述结论是针对经典测量误差的，但它阐明了一个更一般的命题，即如果存在解释变量的测量误差，则OLS估计量即使在大样本下仍是有偏的。

变量的测量误差：当解释变量的测量存在误差时，OLS估计量会存在变量测量偏误。该偏误取决于测量误差的性质，且当样本容量较大时依然存在。如果测量的变量等于其真实值加上一个零均值且独立分布的测量误差，则一元回归的OLS估计量具有偏向零的偏差。

Y的测量误差。Y的测量误差所造成的影响不同于X的测量误差。如果Y具有经典测量误差，则该测量误差会导致回归方差和$$\hat{\beta}_1$$的方差增大，但不会引起$$\hat{\beta}_1$$产生偏差。为了理解这一点，假设$$Y_i$$的测量值为$$\tilde{Y}_i$$，$$\tilde{Y}_i$$等于真实值$$Y_i$$加上随机测量误差$$w_i$$，于是估计的回归模型为$$\tilde{Y}_i = \beta_0 +\beta_1 X_i + v_i$$，其中$$v_i = w_i + u_i$$。如果$$w_i$$是真正随机的，则$$w_i$$和$$X_i$$是独立分布的，从而$$E(w_i \mid X_i) = 0$$，此时$$E(v_i \mid X_i)=0$$，故$$\hat{\beta}_1$$是无偏的。然而，由于$$Var(v_i) > Var(u_i)$$，所以$$\hat{\beta}_1$$的方差大于不存在测量误差时的方差。在测试成绩-班级规模的例子中，假设测试成绩中存在完全随机的判分误差，且与回归变量相互独立，则本段所讨论的经典测量误差模型适用于该例中的$$\tilde{Y}_i$$，且得到的$$\hat{\beta}_1$$是无偏的。更为一遍地，在给定解释变量时，Y测量误差的条件均值为零，故不会引起OLS系数估计量的偏差。

变量测量偏误的解决方法。解决变量测量偏误的最好方法是得到X的准确测量值。但如果这一点难以实现，我们还可以通过利用一些计量经济学方法来降低变量的测量偏误。

一种方法是利用工具变量回归。它依赖于一个与真实值$$X_i$$相关但与测量误差不相关的变量（“工具”变量）。

另一种方法是建立测量误差的数学模型，且如果可能的话，用得到的公式调整回归估计值。

### 数据缺失和样本选择

数据缺失是经济数据的一个普遍特征。数据缺失是否会对内部有效性构成威胁取决于数据缺失的原因。我们考虑三种情形：(1) 数据缺失是完全随机的；(2) 数据的缺失与X有关；(3) 数据缺失与选择过程有关，而选择过程与Y有关，但不取决于X。

当数据缺失完全随机时，即缺失的原因是随机的，而与X或Y的取值无关，其影响仅仅是减少了样本容量，但不会引起偏差。

当数据缺失是与某个解释变量的取值有关时，其影响也是减少了样本容量而不会引起偏差。

相比于前两种情况，如果数据缺失是由选择过程造成的，即选择过程与被解释变量（Y)相关但不取决于解释变量(X)，则这种选择过程会导致误差项与解释变量相关，由此产生的OLS估计量偏差被称为样本选择偏误（sample selection bias）。

样本选择偏误的解决方法。到目前为止，我们讨论的方法都不能解决样本选择偏误。

### 双向因果关系

之前我们都假定因果关系是从解释变量到被解释变量的（X引起Y）。但如果因果关系同时也是从被解释变量到一个或多个解释变量的（Y引起X），那将会怎样呢？如果是这样的话，因果关系既是“向前的”也是“向后的”，即存在双向因果关系（simultaneous causality）。如果存在双向因果关系，则OLS回归同时包含了正向和逆向两种效应，因此OLS估计量是有偏且不一致的。

双向因果关系将导致解释变量和误差项相关。在测试成绩的例子中，假定我们遗漏了某