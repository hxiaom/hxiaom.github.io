---
layout: post
title: 【Method】深度学习正则化（九）切面距离、正切传播和流形正切分类器
categories: Analytics
---

许多机器学习假设数据位于低维流形附近来克服维数灾难。

一个利用流形假设的早期尝试是切面距离（tangent distance）算法（Simard et al., 1993, 1998）。它是一种非参数的最近邻算法，其中使用的度量不是通用的欧几里得距离，而是根据邻近流形关于聚集概率的知识导出的。这个算法假设我们尝试分类的样本和同一流形上的样本具有相同的类别。由于分类器应该对局部因素（对应于流形上的移动）的变化保持不变，一种合理的度量是将点$$x_1$$和$$x_2$$各自所在流形$$M_1$$和$$M_2$$的距离作为点$$x_1$$和$$x_2$$之间的最近距离。然而这可能在计算上是困难的（它需要解决一个寻找$$M_1$$和$$M_2$$最近点对的优化问题），一种局部合理的廉价替代是使用$$x_i$$点处切平面近似$$M_i$$，并测量两条切平面或一个切平面和点之间的距离。这可以通过求解一个低维线性系统（就流形的维数而言）来实现。当然，这种算法需要指定那些切向量。

受相关启发，正切传播（tangent prop）算法（Simard et al., 1992）训练带有额外惩罚的神经网络分类器，使神经网络的每个输出f(x)对已知的变化因素是局部不变的。这些变化因素对应于沿着的相同样本聚集的流形的移动。这里实现局部不变性的方法是要求$$\bigtriangledown_x f(x)$$与已知