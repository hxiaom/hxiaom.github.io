---
layout: post
title: 【Method】MCMC
categories: Analytics
---

## 原理

随机模拟（或统计模拟）方法有一个很酷的别名是蒙特卡洛方法（Monte Carlo Simulation）。这个方法的发展始于20世纪40年代，和原子弹制造的曼哈顿计划密切相关，当时的几个大牛，包括乌拉姆、冯·诺依曼、费米、费曼、Nicholas Metropolis，在美国洛斯阿拉莫斯实验室研究裂变物质的中子连锁反应的时候，开始使用统计模拟的方法，并在最早的计算机上进行编程实现。

现代的统计模拟方法最早由数学家乌拉姆提出，被Metropolis命名为蒙特卡罗方法，蒙特卡罗是著名的赌场，赌博总是和统计密切关联的，所以这个命名风趣而贴切，很快被大家广泛接受。不过据说费米之前就已经在实验中使用了，但是没有发表。说起蒙特卡罗方法的源头，可以追溯到18世纪，布丰当年用于计算π的著名的投针实验就是蒙特卡罗模拟实验。统计采用的方法其实数学家们很早就知道，但是在计算机出现以前，随机数生成的成本很高，所以该方法也没有实用价值。随着计算机技术在二十世纪后半叶的迅猛发展，随机模拟技术很快进入实用阶段。对那些用确定算法不可行或不可能解决的问题，蒙特卡罗方法常常给人们带来希望。

统计模拟中有一个重要的问题就是给定一个概率分布$$p(x)$$,我们如何在计算机中生成它的样本。一般而言均匀分布Uniform(0,1)的样本是相对容易生成的。通过线性同余发生器可以生成伪随机数，我们用确定性算法生成[0,1]之间的伪随机数序列后，这些序列的各种统计指标和均匀分布Uniform(0,1)的理论计算结果非常接近。这样的伪随机序列就有比较好的统计性质，可以被当成真实的随机数使用。

而我们常见的概率分布，无论是连续的还是离散的分布，都可以基于Uniform(0,1)的样本生成，例如正态分布可以通过著名的Box-Muller变换得到

Box-Muller变换：如果随机变量$$U_1, U_2$$独立且$$U_1, U_2 ~ Uniform(0,1)$$，则

$$Z_0 = \sqrt{-2 ln U_1} cos(2\pi U_2)$$

$$Z_1 = \sqrt{-2 ln U_1} sin(2\pi U_2)$$

则，$$Z_0, Z_1$$独立且服从标准正态分布。

其它几个著名的连续分布，包括指数分布、Gamma分布、t分布、F分布、Beta分布、Dirichlet分布等等，也都可以通过类似的数学变换得到；离散的分布通过均匀分布更加容易生成（更多可参看Sheldon M. Ross 《统计模拟》）。

不过我们并不是总是这么幸运的，当$$p(x)$$的形式很复杂，或者$$p(x)$$是个高维的分布的时候，样本的生成就可能很困难了。譬如有如下的情况

1. $$P(x) = \frac{\widetilde{p}(x)}{\int \widetilde{p}(x)dx}，而$$\widetilde{p}(x)$$我们是可以计算的，但是底下的积分式无法显式计算。

2. $$p(x,y)$$是一个二维的分布函数，这个函数本身计算很困难，但是条件分布$$p(x \mid y) p(y \mid x)$$的计算相对简单；如果p(x)是高维的，这种情形就更加明显。

此时就需要使用一些更加复杂的随机模拟的方法来生成样本。而本文介绍的MCMC和之后介绍的Gibbs Sampling算法就是最常用的两种。这两个方法在现代贝叶斯分析中被广泛使用。要了解这两个算法，我们首先要对马氏链的平稳分布的性质有基本的认识。

### 马氏链及其平稳分布

马氏链的数学定义很简单

$$P(X_{t+1}=x \mid X_t, X_{t-1}, ...) = P(X_{t+1}=x \mid X_t)$$

也就是状态转移的概率只依赖于前一个状态。

我们先来看马氏链的一个具体例子。社会学家经常把人按其经济状况分成3类：下层（lower-class）、中层（middle-class）、上层（upper-class），我们用1，2，3分别代表这三个阶层。社会学家们发现决定一个人的收入阶层的最重要的因素就是其父母的收入阶层。如果一个人的收入属于下层类别，那么他的孩子属于下层收入的概率是0.65，属于中层收入的概率是0.28，属于上层收入的概率是0.07。事实上，从父代到子代，收入阶层的变化的转移概率如下：

|      |       |      | 子代 |      |
| ---- | ----- | ---- | ---- | ---- |
|      | State | 1    | 2    | 3    |
|      | 1     | 0.65 | 0.28 | 0.07 |
| 父代 | 2     | 0.15 | 0.67 | 0.18 |
|      | 3     | 0.12 | 0.36 | 0.52 |


![](/img/2019-04-23-mcmc-1.png)

使用矩阵的表示方式，转移概率矩阵记为

$$ P = \left[
 \begin{matrix}
   1 & 2 & 3 \\
   4 & 5 & 6 \\
   7 & 8 & 9
  \end{matrix}
  \right] \tag{3}$$

假设当前这一代人处在下层、中层、上层的人的比例是概率分布向量$$\pi_0=[\pi_o(1), \pi_0(2), \pi_0(3)]$$，那么他们的子女的分布比例将是$$\pi_1 = \pi_0 P$$，他们的孙子代的分布比例将是$$\pi_2 = \pi_1 P = \pi_0 P^2, ...$$，第n代子孙的收入分布比例将是$$\pi_n = \pi_{n-1} P = \pi_0 P^n$$。

假设初始概率分布为$$\pi_0 = [0.21, 0.68, 0.11]$$，则我们可以计算前n代人的分布状况如下

| 第n代人 | 下层  | 中层  | 上层  |
|---------|-------|-------|-------|
| 0       | 0.210 | 0.680 | 0.110 |
| 1       | 0.252 | 0.554 | 0.194 |
| 2       | 0.270 | 0.512 | 0.218 |
| 3       | 0.278 | 0.497 | 0.225 |
| 4       | 0.282 | 0.490 | 0.226 |
| 5       | 0.285 | 0.489 | 0.225 |
| 6       | 0.286 | 0.489 | 0.225 |
| 7       | 0.286 | 0.489 | 0.225 |
| 8       | 0.286 | 0.489 | 0.225 |
| 9       | 0.286 | 0.489 | 0.225 |
| 10      | 0.286 | 0.489 | 0.225 |
| ...     | ...   | ...   | ...   |

我们发现从第7代人开始，这个分布就稳定不变了，这个是偶然吗？我们换一个初始概率分布$$\pi_0 = [0.75, 0.15, 0.1]$$，继续计算前n代人的分布情况如下

| 第n代人 | 下层  | 中层  | 上层  |
|---------|-------|-------|-------|
| 0       | 0.75  | 0.15  | 0.1   |
| 1       | 0.522 | 0.347 | 0.132 |
| 2       | 0.407 | 0.426 | 0.167 |
| 3       | 0.349 | 0.459 | 0.192 |
| 4       | 0.318 | 0.475 | 0.207 |
| 5       | 0.303 | 0.482 | 0.215 |
| 6       | 0.295 | 0.485 | 0.220 |
| 7       | 0.291 | 0.487 | 0.222 |
| 8       | 0.289 | 0.488 | 0.225 |
| 9       | 0.286 | 0.489 | 0.225 |
| 10      | 0.286 | 0.489 | 0.225 |
| ...     | ...   | ...   | ...   |

我们发现，到第9代人时候，分布又收敛了。最为奇特的是，两次给定不同的初始概率分布，最终都收敛到概率分布$$\pi = [0.286, 0.489, 0.225]$$，也就是说收敛行为和初始概率分布$$\pi_0$$无关。这说明这个收敛行为主要是由概率转移矩阵P决定的。我们计算一下$$P^n$$

$$ P^20 = P^21 = ... =  P^100 = ... = \left[
 \begin{matrix}
   0.286 & 0.489 & 0.225 \\
   0.286 & 0.489 & 0.225 \\
   0.286 & 0.489 & 0.225
  \end{matrix}
  \right] \tag{3}$$

我们发现，当n足够大的时候，这个$$P^n$$矩阵的每一行都是稳定地收敛到$$\pi = [0.286, 0.489, 0.225]$$这个概率分布。自然地，这个收敛现象并非是我们这个马氏链独有的，而是绝大多数马氏链的共同行为，关于马氏链的收敛我们有如下定理：

如果一个非周期马氏链具有转移概率矩阵P，且它的任何两个状态是连通的，那么$$\lim_{n \to \infty} P_{ij}^n$$存在且与i无关，记$$\lim_{n \to \infty} P_{ij}^n = \pi(j)$$，我们有

1. $$ \lim_{n \to \infty} P^n = \left[
 \begin{matrix}
   \pi(1) & \pi(2) & ... & \pi(j) & ... \\
   \pi(1) & \pi(2) & ... & \pi(j) & ... \\
   ... & ... & ... &... & ... \\
   \pi(1) & \pi(2) & ... & \pi(j) & ... \\
    ... & ... & ... &... & ... 
\end{matrix}
\right] \tag{3}$$

2. $$\pi(j) = sum_{i=0}^\infty \pi(i) P_{ij}$$

3. $$\pi$$是方程$$\pi P = \pi$$的唯一非负解，其中

$$\pi = [\pi(1), \pi(2), ..., \pi(j), ...], \sum_{i=0}^\infty \pi_i =1$$

$$\pi$$成为马氏链的平稳分布。

这个马氏链的收敛定理非常重要，所有的MCMC（Markov Chain Monte Carlo）方法都是以这个定理作为理论基础的。

### Markov Chain Monte Carlo (MCMC)

对于给定的概率分布p(x)，我们希望能有便捷的方式生成它对应的样本。由于马氏链能收敛到平稳分布，于是一个很漂亮的想法是：如果我们能构造一个转移矩阵为P的马氏链，使得该马氏链的平稳分布恰好是p(x)，那么我们从任何一个初始状态$$x_0$$出发沿着马氏链转移，得到一个转移序列$$x_0, x_1, x_2, ..., x_n, x_{n+1},...$$，如果马氏链在第n步已经收敛了，于是我们就得到了$$\pi(x)$$的样本$$x_n, x_{n+1},...$$。

这个绝妙的想法在1953年被Metropolis想到了，为了研究粒子系统的平稳性质，Metropolis考虑了物理学中常见的波茨曼分布的采用问题，首次提出了基于马氏链的蒙特卡洛方法，即Metropolis算法，并在最早的计算机上编程实现。

## 参考文献

- LDA数学八卦 Rickjin