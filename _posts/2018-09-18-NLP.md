---
layout: post
title: Natural Language Porcessing With NLTK
categories: Analytics
---

[Natural Language Processing with Python-- Analyzing Text with the Natural Language Toolkit Steven Bird, Ewan Klein, and Edward Loper](http://www.nltk.org/book_1ed/)

* TOC
{:toc}


## 0. Preface 

## 1. Language Processing and Python 

## 2. Accessing Text Corpora and Lexical Resources 

The goal of this chapter is to answer the following questions:

- What are some useful text corpora and lexical resources, and how can we access them with Python?
- Which Python constructs are most helpful for this work?
- How do we avoid repeating ourselves when writing Python code?

### 2.1 Accessing Text Corpora

#### Gutenberg Corpus

Project Gutenberg electronic text archive, which contains some 25,000 free electronic books, hosted at http://www.gutenberg.org/.

#### Web and Chat Text

It is important to consider less formal language as well. NLTK's small collection of web text includes content from a Firefox discussion forum, conversations overheard in New York, the movie script of Pirates of the Carribean, personal advertisements, and wine reviews

#### Brown Corpus

The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University. This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on.

#### Reuters Corpus

The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into two sets, called "training" and "test"; thus, the text with fileid 'test/14826' is a document drawn from the test set. 

#### Inaugural Address Corpus

Inaugural Address Corpus, but treated it as a single text.

#### Annotated Text Corpora

Many text corpora contain linguistic annotations, representing POS tags, named entities, syntactic structures, semantic roles, and so forth. NLTK provides convenient ways to access several of these corpora, and has data packages containing corpora and corpus samples, freely downloadable for use in teaching and research.

![](/img/2018-09-18-NLP-1.png)

#### Corpora in Other Languages

#### Text Corpus Structure

#### Loading your own Corpus

If you have a your own collection of text files that you would like to access using the above methods, you can easily load them with the help of NLTK's PlaintextCorpusReader.

### 2.2 Conditional Frequency Distributions

A conditional frequency distribution is a collection of frequency distributions, each one for a different "condition". The condition will often be the category of the text.

#### Conditions and Events

A frequency distribution counts observable events, such as the appearance of words in a text. A conditional frequency distribution needs to pair each event with a condition. So instead of processing a sequence of words [1], we have to process a sequence of pairs [2]

#### Counting Words by Genre

#### Plotting and Tabulating Distributions

#### Generating Random Text with Bigrams

### 2.3 More Python: Reusing Code

### 2.4 Lexical Resources

A lexicon, or lexical resource, is a collection of words and/or phrases along with associated information such as part of speech and sense definitions. Lexical resources are secondary to texts, and are usually created and enriched with the help of texts.

#### Wordlist Corpora

NLTK includes some corpora that are nothing more than wordlists. 

There is also a corpus of stopwords, that is, high-frequency words like the, to and also that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts.

#### A Pronouncing Dictionary

A slightly richer kind of lexical resource is a table (or spreadsheet), containing a word plus some properties in each row. NLTK includes the CMU Pronouncing Dictionary for US English, which was designed for use by speech synthesizers.

#### Comparative Wordlists

Another example of a tabular lexicon is the comparative wordlist. NLTK includes so-called Swadesh wordlists, lists of about 200 common words in several languages.

#### Shoebox and Toolbox Lexicons

Perhaps the single most popular tool used by linguists for managing data is Toolbox, previously known as Shoebox since it replaces the field linguist's traditional shoebox full of file cards. 

### 2.5 WordNet

WordNet is a semantically-oriented dictionary of English, similar to a traditional thesaurus but with a richer structure. NLTK includes the English WordNet, with 155,287 words and 117,659 synonym sets. We'll begin by looking at synonyms and how they are accessed in WordNet.

#### Senses and Synonyms

#### The WordNet Hierarchy

#### More Lexical Relations

#### Semantic Similarity

### 2.6 Summary

## 3. Processing Raw Text

