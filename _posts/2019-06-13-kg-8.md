---
layout: post
title: 【Method】知识图谱（八）实体消歧
categories: Analytics
---

上一章介绍了实体识别的任务和相关方法，但是实体具有歧义性，因此实体识别的结果很难直接存放到知识图谱中。一方面，同一实体在文本中会有不同的指称，这是指称的多样性（Name Variation）。另一方面，相同的实体指称在不同的上下文中可以指不同的实体，这是指称的歧义性（Name Ambiguation）。因此必须对实体识别的结果进行消歧才能得到无歧义的实体信息。实体消歧是信息抽取和集成领域的一项关键技术，旨在解决文本信息中广泛存在的名字歧义问题，在知识图谱构建、信息检索和问答系统等领域具有广泛的应用价值。

## 任务定义

实体消歧所处理的对象都是命名实体，以下简称实体消歧，可以通过如下六元组进行定义：

$$M=N,E,D,O,K,\delta$$

其中$$N=n_1, n_2, ..., n_l$$是待消歧的实体名集合，例如“李娜”，“迈克尔·乔丹”等。

$$E=e_1, e_2, ..., e_k$$是待消歧实体名的目标实体列表，包括了所有待消歧实体名可能指向的实体，如李娜（网球运动员）、李娜（跳水运动员）、迈克尔·乔丹（NBA巨星）、迈克尔·乔丹（足球运动员）等。在实际应用中，目标实体列表通常以知识库的形式给出，如Wikipedia和Freebase。

$$D=d_1, d_2,...,d_n$$是一个包含了待消歧实体名的文档集，如“迈克尔·乔丹”的前100个Google搜索结果的网页集合。

$$O=o_1, o_2,...,o_m$$是D中所有待消歧的实体指称项集合。本章中，实体指称项表示实体消歧任务的基本单位：一个实体指称项是一个在具体上下文中出现的待消歧实体名。例如“迈克尔·乔丹是NBA最伟大的球星”中的“迈克尔·乔丹”是实体迈克尔·乔丹（NBA巨星）的一个指称项。实体指称项的上下文可以通过多种方式自由定义，如实体出现位置的一个指定大小窗口内的文本，或是实体名所在的整篇文本等。

K是命名实体消歧任务所使用的背景知识。由于实体名本身所携带的信息不足以支撑实体消歧任务，消歧系统需要大量背景知识，其中最常用的背景知识是关于目标实体的文本描述。近年来，随着命名实体消歧研究的进展，越来越多的背景知识被用于命名实体消歧：从实体描述文本，到社会化网络中蕴含的实体社会化关联知识，再到概念之间的语义关联知识。

$$\delta : O \times K \to E$$是命名实体消歧函数，用于将待消歧的实体指称项映射到目标实体列表（如果E是显示给定的）或者按照其指向的目标实体进行聚类（如果E没有显示给定，是隐藏变量）。命名实体消歧函数是命名实体消歧任务的核心部分，直接影响系统的性能。

## 任务分类

按照不同的分类维度，实体消歧系统可以有多种分类方法，按照目标实体列表是否给定，实体消歧系统可以分为基于聚类的消歧系统和基于实体链接的消歧系统；按照实体消歧任务的领域不同，实体消歧任务可以分为结构化文本实体消歧和非结构化文本实体消歧系统。

(1) 基于聚类的实体消歧系统。由于目标实体列表没有给定，基于聚类的命名实体消歧系统以聚类方式对实体指称项进行消歧。所有指向同一个目标实体的指称项被消歧系统聚在同一类别下，聚类结果中每一个类别对应一个目标实体。

(2) 基于实体链接的实体消歧系统。基于实体链接的命名实体消歧系统通过将实体指称项与目标实体列表中的对应实体进行链接实现消歧。由于目标实体列表中的实体是无歧义的，链接之后的指称项也就能自动消除歧义。

## 相关评测

目前主流的命名实体消歧评测平台主要有两个：一个是WePS（Web Person Search Clustering Task）评测，主要针对基于聚类的命名实体消歧系统进行评测；第二个是TAC KBP的Entity Linking评测，主要针对基于实体链接的命名实体消歧系统进行评测。

(1) WePS评测

WePS的评测指标主要有Purity（纯净度）、Inverse Purity（倒纯净度）和F值。

(2) TAC KBP评测

实体链接评测任务近似于跨文档共指消解，但是由于其任务是链接到目标实体，而不是对指称项进行聚类，因此主要评测指标是Micro-averageed accuracy，即所有链接结果的平均准确率，计算公式如下

$$Micro = \frac{\sum_{q \in Q} \delta [L(q), C(q)]}{\mid Q \mid}$$

其中，Q是所有查询的集合，L(q)是实体链接系统给出的查询q的目标实体ID，C(q)是查询q的准确目标实体ID，$$\delta$$用于判断L(q)是否与C(q)相同，相同则为1，不相同则为0。

## 基于聚类的实体消歧方法

在目标实体没有给定的情况下，目前绝大多数系统都采用聚类方法进行命名实体消歧。给定待消歧的实体指称项集合$$O=o_1, o_2, ..., o_k$$，以聚类方式实现消歧的系统按如下步骤进行消歧。

(1) 对每一个实体指称项o，抽取其特征（如上下文中的词、实体、概念），并将其表示成特征向量$$o=w_1, w_2, ..., w_n$$。

(2) 计算实体指称项之间的相似度。

(3) 采用某种聚类算法对实体指称项聚类，使得聚类结果中每一个类别都对应到一个目标实体上。

以聚类方式实现消歧的关键问题是计算指称项之间的相似度。按照实体指称项相似度计算方法的不同，基于聚类的实体消歧系统可以分为如下三类：(1) 基于表层特征的实体指称项相似度计算；(2) 基于扩展特征的实体指称项相似度计算；(3) 基于社会化网络的实体指称相似度计算。

### 基于表层特征的实体指称项相似度计算

传统方法中大多数实体消歧系统都只利用指称项的表层特征来计算相似度。这些方法通常是词袋模型（Bag of Words, BoW）的自然延伸，难以取得良好的实体消歧性能。给定一个实体指称项，基于词袋模型的实体消歧系统首先将其表示为Term向量的形式，其中每个Term的权重通常采用经典TF-IDF算法进行计算。基于实体指称项的Term向量表示，实体消歧系统通常使用向量的Cosine相似度来计算实体指称项之间的相似度。

### 基于扩展特征的实体指称项相似度计算

为了克服基于表层特征指称项相似度的缺陷，一些研究工作开始使用知识资源来提升实体消歧的性能。其中，最直接的方法是使用知识资源来扩展实体指称项的特征表示。例如，除了传统的上下文词特征之外，Mann等和Chen等通过抽取人物的传记属性来扩展表示人物指称项，这些属性包括birthday、birth year、occupation等。这些抽取出来的属性信息通常有两个作用：(1) 作为实体指称项的扩展特征；(2) 由于这些属性信息提供了更准确的实体指称项信息，它们也能用来重构聚类结果。

### 基于社会化网络的实体指称项相似度计算

与基于表层特征和基于扩展特征的实体指称项相似度不同，基于社会化网络的实体指称项相似度通常使用基于图的算法，能够充分利用社会化网络的传递性，从而考虑隐藏的关系知识，在某些情况下（特别是结构化数据，如论文记录、电影记录等）能够取得更为准确的实体指称项相似度计算结构。但是，基于社会化网络的相似度度量的缺点在于它只用到上下文中的实体信息，不能完全利用实体指称项的其他上下文信息，因此通常不能在文本实体消歧领域取得有竞争力的性能。

在社会化关系图表示框架下，实体指称项之间的相似度通常使用图算法中的随机游走算法来计算。目前已有很多基于社会化网络的命名实体消歧研究。Malin等和Yang等首先基于语料库内实体的共现关系建立一个社会化网络，然后基于一个实体到另一个实体在网络中的随机游走概率来计算它们之间的相似度；Minkov等研究电子邮件数据中的实体消歧问题：首先基于邮件数据建立实体的社会化网络，然后利用随机步算法计算实体之间的相似度。

## 基于实体链接的实体消歧方法

基于实体链接的实体消歧方法，一般是将实体指称项链接到知识库中特定的实体，也称为实体链接。实体链接（通常称为Entity Linking，与Entity Grounding，Entity Resolution，Record Linkage和Entity Disambiguation意思接近）指的是将一个命名实体的文本指称项（Textual Mention）链接到知识库中相应实体的过程（知识库中更可能不包含待消歧指称项的对应实体，这时，将实体指称项链接到空实体NIL）。

通常，实体链接的输入包括两个部分。

(1) 目标实体知识库

(2) 待消歧实体指称项及其上下文信息。

实体链接任务通常需要两个步骤。

(1) 链接候选过滤（Blocking）：由于一个知识库中通常包含上百万个实体，在实际的实体链接任务中不可能计算一个指称项与所有实体之间进行链接的可能性。因此，实体链接需要首先根据规则或知识过滤掉大部分该指称项不可能指向的实体，仅仅保留少量链接实体候选。

(2) 实体链接（Linking）：给定指称项及其链接候选，实体链接的第二个步骤是确定该实体指称项最终指向的目标实体。

### 链接候选过滤方法

目前还缺少对链接候选过滤方法的系统化研究和量化分析，大部分工作都是基于实体指称项词典：通过在词典中记录一个指称项所有可能指向的目标实体来进行链接候选过滤。传统实体链接方法通常使用Wikipedia等知识资源来构建指称项词典。

### 实体链接方法

给定一个指称项m及其候选链接$$E=e_1, e_2,...,e_n$$，实体链接方法选择与指称项具有最高一致性打分的实体作为其目标实体：

$$e=arg \max_e Score(e,m)$$

根据如何计算$$Score(e,m)$$，现有的方法可以分为四种：向量空间模型、主题一致性模型、协同实体链接模型和基于神经网络的模型。

1. 向量空间模型

在向量空间模型中，实体指称项与目标实体的一致性打分主要基于实体指称项上下文与目标实体上下文中特征的共现信息来确定。在该模型中，实体概念和实体指称项都被表示为上下文中Term组成的向量（Term通常为词，还可能包括概念、类别等）。基于Term向量表示，向量空间模型通过计算两个向量之间的相似度对实体概念和指称项之间的一致性进行打分。

目前，针对向量空间的研究集中在两个方面：(1) 如何抽取有效的特征表示；(2) 如何更为有效地计算向量之间的相似度。

2. 主题一致性模型

在主题一致性模型中，决定一致性打分的是实体指称项的候选实体概念与指称项上下文中的其他概念的一致性程度。

在计算一致性打分时，通常需要考虑如下两个因素：

(1) 上下文实体的重要程度；在实体指称项上下文实体中，并不是所有的实体都提供了相同的上下文信息。其中有些实体提供了很少的上下文信息，如新闻报道中经常出现的实体sina、sohu等媒体。由于这些实体在许多文档中都会出现，它们往往比其他的实体提供了更少的信息；另外一些实体只在于其主题相关的文档中出现，也就提供了更多的关于文档主题的信息。传统方法使用实体与文本内其他实体的语义关联的平均值作为其重要程度的打分：

$$w(e,o) = \frac{\sum_{e_i \in O} sr(e, e_i)}{\mid O \mid}$$

其中，O是实体指称项上下文中所有实体的集合，$$sr(e, e_i)$$是实体e和实体$$e_i$$之间的语义关联值，通常基于知识资源计算。

(2) 如何计算一致性：给定上下文中实体集合，如何计算目标实体与实体指称项上下文的一致性也是一个重要的研究问题。目前，大部分计算方法使用目标实体与上下文中其他实体的加权语义关联平均作为其一致性打分，即：

$$Coherence(e,o) = \frac{\sum_{e_i \in O} w(e,o) sr(e,e_i)}{\sum_{e_i \in O} w(e,o)}$$

3. 协同实体链接

上述向量空间模型和主题一致性模型都只能处理单个实体指称项的链接问题，而忽略了单篇文档内所有实体指称项的目标实体之间的关系。考虑到文档的主题一致性，一篇文档内的所有实体指称项的目标实体也应该是相互关联的。因此对单篇文章内所有实体指称项进行协同链接有助于提升实体链接的性能。

Kulkarni等提出了一种协同实体链接的方法，它把单篇文档的协同实体链接看成一个优化任务，其优化任务的目标函数由如下公式决定：

$$