---
layout: post
title: 【Method】深度学习正则化（二）数据增强&噪声鲁棒性
categories: Analytics
---

## 原理

### 数据集增强

让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。当然，在实践中，我们拥有的数据量是很有限的。解决这个问题的一种方法是创造假数据并添加到训练集中。对于一些机器学习任务，创建新的假数据相当简单。

对于分类来说这种方法是最简单的。分类器需要一个复杂的高维输入x，并用单个类别标识y概括x。这意味着分类面临的一个主要任务是要对各种各样的变化保持不变。我们可以轻易通过转换训练集中的x来生成新的(x,y)对。

这种方法对于其他许多任务来说并不那么容易。例如，除非我们已经解决了密度估计问题，否则在密度估计任务中生成新的假数据是很困难的。

数据集增强对一个具体的分类问题来说是特别有效的方法：对象识别。图像是高维的并包括各种巨大的变化因素，其中有许多可以轻易地模拟。即使模型已经使用卷积和池化技术对部分平移保持不变，沿训练图像每个方向平移几个像素的操作通常可以大大改善泛化。许多其他操作如旋转图像或缩放图像也已被证明非常有效。

我们必须小心，不能使用会改变类别的转换。例如，光学字符识别任务需要认识到“b”和“d”以及“6”和“9”的区别。所以对这些任务来说，水平翻转和旋转180°并不是合适的数据集增强方式。

能保持我们希望的分类不变，但不容易执行的转换也是存在的。例如，平面外绕轴转动难以通过简单的集合运算在输入像素上实现。

在神经网络的输入层注入噪声（sietsma and Dow，1991）也可以看作数据增强的一种方式。对于许多分类甚至一些回归任务而言，即使小的随机噪声被加到输入，任务仍应该是能够被解决的。然而，神经网络被证明对噪声不是非常健壮（Tang and Eliasmith，2010）。改善神经网络健壮性的方法之一是简单地将随机噪声添加到输入再进行训练。输入噪声注入是一些无监督学习算法的一部分，如去噪自编码器（Vincent et al., 2008a）。向隐藏单元施加噪声也是可行的，这可以被看作在多个抽象层上进行的数据集增强。Poole et al. (2014)最近表明，噪声的幅度被细心调整后，该方法是非常高效的。我们将在之后介绍一个强大的正则化策略Dropout，该策略可以看作通过与噪声相乘构建新输入的过程。

在比较机器学习基准测试的结果时，考虑其采取的数据集增强是很重要的。通常情况下，人工设计的数据集增强学习方案可以大大减少机器学习技术的泛化误差。将一个机器学习算法的性能与另一个进行比较时，对照实验是必要的。在比较机器学习算法A和机器学习算法B时，应该确保这两个算法使用同一人工转换的数据后表现良好。假设算法A在没有数据集增强时表现不佳，而B结合大量人工转换的数据后表现良好。在这样的情况下，很可能是合成转换引起了性能改进，而不是机器学习算法B比算法A更好。有时候，确定实验是否已经适当控制需要主观判断。例如，向输入注入噪声的机器学习算法是执行数据集增强的一种形式。通常，普适操作（例如，向输入添加高斯噪声）被认为是机器学习算法的一部分，而特定于一个应用领域（如随机地裁剪图像）的操作被认为是独立的预处理步骤。

### 噪声鲁棒性

