---
layout: post
title: 【Method】回归分析专题（三）工具变量回归
categories: Analytics
---

前面的章节我们讨论了变量遗漏、变量的测量误差及双向因果关系等导致回归误差项与解释变量相关的问题。其中，变量遗漏偏差可通过在多元回归中加入遗漏变量来解决，但该方法的前提是能够获取相应数据；当存在由Y到X和由X到Y的双向因果偏差时，简单多元回归无法解决该问题，从而需要寻找一种新的方法。

工具变量（instrumental variable，IV）回归是当解释变量X与误差项u相关时，得到总体回归系数一致估计量的一种一般性方法。为理解工具变量回归的原理，将X的变动分为两部分：一部分与u相关（引发问题的部分）；另一部分与u无关。一旦能够分离出第二部分的信息，就可以集中研究这些与u无关的X的变动，而忽略那部分使OLS估计量有偏的X的变动。这就是工具变量回归所做的事情，即从一个或多个附加变量中收集与u无关的X变动信息，这些附加变量称为工具变量（instrumental variables）或工具（instruments）。工具变量回归用附加变量作为手段或“工具”分离出X变动信息中与u无关的部分，从而使回归系数估计量具有一致性。

## 单个自变量和单个工具变量的工具变量估计量

首先考虑可能与回归误差u相关的一元解释变量X的情形。若X与u相关，则OLS估计量不一致，即使当样本容量很大时，OLS估计量也不会接近回归系数的真值。产生X与u之间的相关性的原因是多方面的，包括变量遗漏、变量误差（如测量误差）及双向因果关系（不仅是从Y到X“向前”的因果关系，也是从X到Y“向后”的因果关系）。不论该相关性的来源是什么，只要找到一个有效的工具变量Z，就可以通过工具变量法来估计X变化1个单位对Y的影响。

### 工具变量回归模型和假设

被解释变量$$Y_i$$和解释变量$$X_i$$的总体回归模型为：

$$Y_i = \beta_0 + \beta_1 X_i + u_i, i=1, ...,n$$

同前，其中$$u_i$$是误差项，代表除X外其他决定$$Y_i$$的遗漏因素。若$$X_i$$与$$u_i$$相关，则OLS估计量不一致，而工具变量估计则可以利用“工具”变量Z分离出X中与$$u_i$$不相关的部分。

1.内生性与外生性

在工具变量回归中有特定术语来区分与总体误差项u相关和不相关的变量。与误差项相关的变量称为内生变量（endogenous variable），与误差项不相关的变量则被称为外生变量（exogenous variable）。这些术语的来源可追溯到包含多个方差的模型，其中“内生”变量是由模型内部决定的，“外生”变量是由模型外部决定的。

2.工具变量有效的两个条件

一个有效的工具变量（“工具”）必须满足两个条件，即工具相关条件（instrument relevance condition）和工具外生条件（instrument exogeneity condition）：

(1) 工具变量相关：$$corr(Z_i, X_i) \neq 0$$

(2) 工具变量外生：$$corr(Z_i, u_i) = 0$$

如果工具变量满足相关条件，则工具变量的变动与$$X_i$$的变动有关：如果工具变量满足外生性条件，则它能够捕捉到$$X_i$$变动中的外生变动部分。于是，满足相关性和外生性条件的工具变量捕捉到$$X_i$$中的外生变动，从而可用该外生变动来估计系数$$\beta_1$$。

上述工具变量有效的条件对工具变量回归而言至关重要，本章将反复提到这一点（并推广到多个解释变量和多个工具变量的情形）。

### 两阶段最小二乘估计量

若工具变量Z满足相关性和外生性条件，则系数$$\beta_1$$的估计可以通过两阶段最小二乘（two stage least squares，TSLS）的工具变量估计来实现。顾名思义，两阶段最小二乘估计量是分两个阶段计算得出的。其中，第一阶段把X分解为两部分：一是与回归误差相关而引发问题的部分；二是与误差无关而不会引发问题的部分。第二阶段使用不会引发问题的部分估计$$\beta_1$$。

第一阶段是建立如下的回归模型：

$$X_i = \pi_0 + \pi_1 Z_i + v_i$$

式中，$$\pi_0$$为截距；$$\pi_1$$为斜率；$$v_1$$为误差项。

该回归对$$X_1$$进行了必要的分解。其中一部分为$$\pi_0 + \pi_1 Z_i$$，即可由$$Z_i$$预测出的部分。由于$$Z_i$$是外生的，该部分$$X_i$$与误差项$$u_i$$无关。$$X_i$$的另一部分为$$v_i$$，它是$$X_i$$中与$$u_i$$相关从而引起问题的部分。

两阶段最小二乘法背后的思想是利用$$X_i$$中不引起问题的部分$$\pi_0 + \pi_1 Z_i$$，而忽略$$v_i$$。该方法的复杂之处在于$$\pi_0$$和$$\pi_1$$的值是未知的，故无法计算$$\pi_0 + \pi_1 Z_i$$。因此，在第一阶段中，我们利用OLS估计并取OLS回归的预测值$$\hat{X}_i = \hat{\pi}_0 + \hat{\pi}_1 Z_i$$，其中$$\hat{\pi}_0$$和$$\hat{\pi}_1$$为OLS估计量。

两阶段最小二乘法的第二阶段非常简单：使用OLS建立$$Y_i$$关于$$\hat{X}_i$$的回归，由此得到的估计量即为两阶段最小二乘估计量$$\hat{\beta}^{TSLS}_0$$和$$\hat{\beta}^{TSLS}_1$$。

### TSLS估计量的抽样分布

小样本情形下的TSLS估计量的精确分布十分复杂，但其与OLS估计量一样，其在大样本下的分布则较为简单：TSLS估计量是一致的且服从正态分布。

TSLS估计量的公式。虽然TSLS的两阶段看似使估计复杂化了，但仅考虑一个解释变量X和一个工具变量Z时，TSLS估计量有一个较简单的公式。令$$s_{ZY}$$表示Z和Y之间的样本协方差，$$s_{ZX}$$表示Z和X之间的样本协方差。一元工具变量TSLS估计量为

$$\hat{\beta}^{TSLS}_1 = \frac{s_{ZY}}{s_{ZX}}$$

即$$\beta_1$$的TSLS估计量为Z和Y的样本协方差与Z和X的样本协方差之比。