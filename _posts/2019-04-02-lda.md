---
layout: post
title: 【Method】Topic Model（三）LDA
categories: Analytics
---

## 目的

获得文章的主题

## 原理

LDA是基于贝叶斯模型的，涉及到贝叶斯模型离不开“先验分布”，“数据（似然）”和"后验分布"三块。

- 先验概率：先验概率（prior probability）是指根据以往经验和分析得到的概率，如全概率公式，它往往作为"由因求果"问题中的"因"出现的概率。

- 似然函数

Probability is used to describe the plausibility of some data, given a value for the parameter. Likelihood is used to describe the plausibility of a value for the parameter, given some data.

- 后验概率

- 共轭分布


### LDA模型

在LDA模型中，我们的目标是找到每一篇文档的主题分布和每一个主题中词的分布。在LDA模型中，我们需要先假设一个主题数目K，这样所有的分布就都基于K个主题展开。那么具体LDA模型是怎么样的呢？

![](/img/2019-04-02-lda-1.png)

LDA假设文档主题的先验分布是Dirichlet分布，即对于任一文档d，其主题分布$$\theta_d$$为：

$$\theta_d = Dirichlet(\overrightarrow{\alpha})$$

其中，$$\alpha$$为分布的超参数，是一个K维向量。

LDA假设主题中词的先验分布是Dirichlet分布，即对于任一主题k，其词分布$$\beta_k$$为：

$$\beta_d = Dirichlet(\overrightarrow{\eta})$$

其中，$$\eta$$为分布的超参数，是一个V维向量。V代表词汇表里所有词的个数。

对于数据中任意一篇文档d中的第n个词，我们可以从主题分布$$\theta_d$$中得到它的主题编号$$z_{dn}$$的分布为：

$$z_{dn} = multi(\theta_d)$$

而对于该主题编号，得到我们看到的词$$w_{dn}$$的概率分布为：

$$w_{dn} = multi(\beta_{z_{dn}})$$

理解LDA主题模型的主要任务就是理解上面的这个模型。这个模型里，我们有M个文档主题的Dirichlet分布，而对应的数据有M个主题编号的多项分布，这样$$(\alpha \to \theta_d \to \overrightarrow{z}_d)$$就组成了Dirichlet-multi共轭，可以使用前面提到的贝叶斯推断的方法得到基于Dirichlet分布的文档主题后验分布。

如果在第d个文档中，第k个主题的词的个数为：$$n_d^{(k)}$$，则对应的多项分布的计数可以表示为




## 参考文献

- [文本主题模型之LDA(一) LDA基础](https://www.cnblogs.com/pinard/p/6831308.html)
- [百度百科：先验概率](https://baike.baidu.com/item/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87/6106649?fr=aladdin)
- [共轭先验、共轭分布——为LDA做准备](https://www.jianshu.com/p/bb7bce40a15a)
- [LDA数学八卦](http://www.flickering.cn/数学之美/2014/06/lda数学八卦lda-文本建模/)
- Mimno D, Wallach H M, Talley E, et al. Optimizing semantic coherence in topic models[C]//Proceedings of the conference on empirical methods in natural language processing. Association for Computational Linguistics, 2011: 262-272.
- [Topic models and word co-occurrence methods](https://stats.stackexchange.com/questions/32310/topic-models-and-word-co-occurrence-methods)

https://www.zhihu.com/question/54082000