---
layout: post
title: 【Method】HMM（一）基本概念
categories: Analytics
---

## 原理

隐马尔科夫模型（hidden Markov model，HMM）是可用于标注问题的统计学习模型，描述由隐藏的马尔科夫随机生成观测序列的过程，属于生成模型。

### 隐马尔科夫模型的基本概念

隐马尔科夫模型：隐马尔科夫模型是关于时序的概率模型，描述由一个隐藏的马尔科夫随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔科夫链随机生成的状态的序列，称为状态序列（state sequence）；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（observation sequence）。序列的每一个位置又可以看作是一个时刻。

隐马尔科夫模型由初始概率分布、状态转移概率分布以及观测概率分布确定。隐马尔可夫模型的形式定义如下：

设Q是所有可能的状态的集合，M是可能的观测数。

I是长度为T的状态序列，O是对应的观测序列。

$$I=(i_1, i_2, ..., i_T), O=(o_1, o_2, ..., o_T)$$

A是状态转移概率矩阵：

$$A = [a_{ij}]_{N \times N}$$

其中，

$$a_{ij} = P(i_{t+1} = q_j \mid i_t = q_i), i=1,2,...,N; j=1,2,...,N$$

是在时刻t处于状态$$q_i$$的条件下在时刻t+1转移到状态$$q_j$$的概率。

B是观测概率矩阵：

$$B = [b_j(k)]_{N \times N}$$

其中，

$$b_j(k) = P(o_t = v_k \mid i_t = q_j), k=1,2,...,M; j=1,2,...,N$$

是在时刻t处于状态$$q_j$$的条件下生成观测$$v_k$$的概率。

$$\pi$$是初始状态概率向量：

$$\pi = (\pi_i)$$

其中，

$$\pi_i = P(i_1 = q_i), i=1,2,...,N$$

是时刻t=1处于状态$$q_i$$的概率。

隐马尔可夫模型由初始状态概率向量$$\pi$$，状态转移概率矩阵A和观测概率矩阵B决定。$$\pi$$和A决定状态序列，B决定观测序列。因此，隐马尔可夫模型$$\lambda$$可以用三元符号表示，即

$$\lambda = (A,B,\pi)$$

$$A,B,\pi$$称为隐马尔科夫模型的三要素。

状态转移概率矩阵A与初始状态概率向量$$\pi$$确定了隐藏的马尔科夫链，生成不可观测的状态序列。观测概率矩阵B确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。

从定义可知，隐马尔可夫模型作了两个基本假设：

（1）齐次马尔可夫假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻t无关。

$$P(i_t \mid i_{t-1}, o_{t-1},..., i_1, o_1) = P(i_t \mid i_{t-1}), t=1,2,...,T$$

（2）观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关。

$$P(o_t \mid i_T, o_T, i_{T-1}, o_{T-1},..., i_{t+1}, o_{t+1}, i_t, i_{t-1}, o_{t-1},...,i_1, o_1) = P(o_t \mid i_t)$$

隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测的序列预测其对应的标记序列。可以假设标注问题的数据是由隐马尔可夫模型生成的。这样我们可以利用隐马尔可夫模型的学习与预测算法进行标注。

#### 观测序列的生成过程

根据隐马尔可夫模型定义，可以将一个长度为T的观测序列$$O=(o_1, o_2, ..., o_T)$$的生成过程描述如下：

输入：隐马尔可夫模型$$\lambda = (A,B,\pi)$$，观测序列长度T；

输出：观测序列$$O=(o_1, o_2, ..., o_T)$$

(1) 按照初始状态分布$$\pi$$产生状态$$i_1$$

(2) 令t=1

(3) 按照状态$$i_t$$的观测概率分布$$b_{i_t}(k)$$生成$$o_t$$

(4) 按照状态$$i_t$$的状态转移概率分布$${a_{i_t i_{t+1}}}$$产生状态$$i_{t+1}, i_{t+1}=1,2,...,N$$

(5) 令t=t+1；如果t<T，转步骤(3)；否则，终止。

#### 隐马尔可夫模型的3个基本问题

隐马尔可夫模型有3个基本问题：

(1) 概率计算问题。给定模型$$\lambda=(A,B,\pi)$$和观测序列$$O=(o_1, o_2,...,o_T)$$，计算在模型$$\lambda$$下观测序列O出现的概率$$P(O \mid \lambda)$$。

(2) 学习问题。已知观测序列$$O=(o_1, o_2, ..., o_T)$$，估计模型$$\lambda = (A,B,\pi)$$参数，使得在该模型下观测序列概率$$P(O\mid \lambda)$$最大。即用极大似然估计的方法估计参数。

(3) 预测问题，也称为解码（decoding）问题。已知模型$$\lambda = (A,B,\pi)$$和观测序列$$O=(o_1, o_2, ..., o_T)$$，求对给定的观测序列条件概率$$P(I \mid O)$$最大的状态序列$$I=(i_1, i_2, ..., i_T)$$。即给定观测序列，求最有可能的对应的状态序列。